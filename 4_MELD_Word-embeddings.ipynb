{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c09547e-9a7d-4fb5-94ca-1e87df66694b",
   "metadata": {},
   "source": [
    "# 4. MELD, Word-embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edd1c61-f66c-460b-931d-6e807aa337bc",
   "metadata": {},
   "source": [
    "## 4.1 Data preparation and filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa8ab59-711a-4164-80aa-dfee54270eb9",
   "metadata": {},
   "source": [
    "(a) Loading the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5aa507a-366a-4056-a489-2421e4781ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab521505-7767-4fd4-a82f-dcc0e66ae8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-6ff697eb93e3>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  meld_dftrain['Utterance'] = meld_dftrain['Utterance'].str.replace(\"\\x92|\\x97|\\x91|\\x93|\\x94|\\x85\", \"'\")\n",
      "<ipython-input-2-6ff697eb93e3>:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  meld_dftest['Utterance'] = meld_dftest['Utterance'].str.replace(\"\\x92|\\x97|\\x91|\\x93|\\x94|\\x85\", \"'\")\n"
     ]
    }
   ],
   "source": [
    "filepath = './data/MELD/train_sent_emo.csv'\n",
    "meld_dftrain = pd.read_csv(filepath)\n",
    "meld_dftrain['Utterance'] = meld_dftrain['Utterance'].str.replace(\"\\x92|\\x97|\\x91|\\x93|\\x94|\\x85\", \"'\")\n",
    "\n",
    "filepath = './data/MELD/test_sent_emo.csv'\n",
    "meld_dftest = pd.read_csv(filepath)\n",
    "meld_dftest['Utterance'] = meld_dftest['Utterance'].str.replace(\"\\x92|\\x97|\\x91|\\x93|\\x94|\\x85\", \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7004ef-36de-4b5e-b361-36a5beacac25",
   "metadata": {},
   "source": [
    "(b) MELD data preprocessing: removing 'Neutral' utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89875cd7-9a11-4ec0-8f79-9c5cd98af7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "meld_dftrain = meld_dftrain.set_index(\"Emotion\", drop=False)\n",
    "meld_dftrain = meld_dftrain.drop(\"neutral\", axis=0)\n",
    "\n",
    "meld_dftest = meld_dftest.set_index(\"Emotion\", drop=False)\n",
    "meld_dftest = meld_dftest.drop(\"neutral\", axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bd1da9-95b2-4009-9ebd-6df497e193c3",
   "metadata": {},
   "source": [
    "(c) Tokenizing and filtering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdb222ae-9266-485d-8e29-b03391400cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using spaCy to tokenize the sentences\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "                 \n",
    "training_data_4 = [nlp(sent) for sent in list(meld_dftrain['Utterance'])]\n",
    "training_labels_4 = list(meld_dftrain['Emotion'])\n",
    "\n",
    "test_data_4 = [nlp(sent) for sent in list(meld_dftest['Utterance'])]\n",
    "test_labels_4 = list(meld_dftest['Emotion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a29853-de60-4110-99d9-4b5745389cb4",
   "metadata": {},
   "source": [
    "### Filter A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4686137-7d97-4622-b1ba-047b6b0c9d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_df 2\n",
      "Max_df 527\n",
      "Rare words with low df =  1680 words. Examples:  ['paolo', 'liking', 'safety', 'juice', 'crime', 'series', \"or'oh\", '12', 'thquirt', 'pushover', 'we?re', 'greet', 'surgeon', 'law', 'chuck', 'bend', 'expressly', 'hooohhh', '22', 'coyote']\n",
      "Stop words with high df: {'a', 'and', 'be', 'to', 'the', 'i', ',', 'you', '.', '!', 'what', 'that', '?', 'do', 'it', \"n't\", 'oh'}\n",
      "Size of the rest vocab: 1530\n",
      "Samples: [['just', 'coffee', 'where', 'we', 'gon', 'na', 'hang', 'out', 'now'], ['got'], [], ['um', '-', 'mm', 'yeah', 'right'], ['my', 'god', 'my', 'god', 'poor', 'monica'], [], [], ['he', 'think', 'monica', 'empty', 'she', 'empty', 'vase'], ['totally', 'god', 'she', 'seem', 'so', 'happy', 'too'], ['hey']]\n"
     ]
    }
   ],
   "source": [
    "from utils import low_high_mid_df\n",
    "min_df = 2\n",
    "max_df = len(training_data_4)//10\n",
    "\n",
    "low_df, high_df, clean4A = low_high_mid_df(min_df, max_df, training_data_4)\n",
    "\n",
    "print(\"Rare words with low df = \", len(low_df), \"words. Examples: \", list(low_df)[:20])\n",
    "print(\"Stop words with high df:\", high_df)\n",
    "vocab_4A = set()\n",
    "for sent in clean4A:\n",
    "    for t in sent:\n",
    "        vocab_4A.add(t)\n",
    "print(\"Size of the rest vocab:\", len(vocab_4A))\n",
    "print(\"Samples:\", clean4A[10:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb8dec7-a76b-4310-b988-473c38505150",
   "metadata": {},
   "source": [
    "### Filter B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e446e76-b2bc-462f-9436-33c93becb0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determiner and pronouns {'she', \"underwear'you\", \"i'll\", \"you're\", \"was'the\", 'no', 'yours', \"you're'you\", 'his', \"it's\", 'some', 'you', 'tux', \"i'm\", 'their', 'i-', 'themselves', 'either', 'this', \"mean'i\", 'both', \"'em\", 'a', \"i'y'know\", \"fact'yes\", 'the', 'they', 'ours', 'that', 'neither', \"film'that\", 'those', \"'s\", 'mine', 'ya', 'each', 'myself', 'all', 'hers', 'i', 'that?s', 'its', 'her', \"i'i'm\", \"that'you\", \"up'i\", 'your', 'itself', 'ourselves', 'ba', 'my', 'the-', 'any', 'we', 'our', 'he', 'every', 'another', 'it', 'herself', 'an', 'yourself', 'these'}\n",
      "Min_df 2\n",
      "Rare words with low df =  1670 words. Examples: ['paolo', 'liking', 'safety', 'juice', 'crime', 'series', \"or'oh\", '12', 'thquirt', 'pushover', 'we?re', 'greet', 'surgeon', 'law', 'chuck', 'bend', 'expressly', 'hooohhh', '22', 'coyote']\n",
      "Size of the rest vocab: 1515\n",
      "Samples: [['just', 'coffee', '!', 'where', 'be', 'gon', 'na', 'hang', 'out', 'now', '?'], ['got', '.'], ['!'], ['um', '-', 'mm', ',', 'yeah', 'right', '!'], ['oh', 'my', 'god', ',', 'oh', 'my', 'god', '!', 'poor', 'monica', '!'], ['what', ',', 'what', ',', 'what', '?', '!'], ['what', '?', '!'], ['think', 'monica', 'be', 'empty', ',', 'be', 'empty', 'vase', '!'], ['oh', ',', 'totally', '.', 'oh', ',', 'god', ',', 'oh', ',', 'seem', 'so', 'happy', 'too', '.'], ['hey', '!']]\n"
     ]
    }
   ],
   "source": [
    "from utils import remove_DT_PRP\n",
    "\n",
    "min_df = 2\n",
    "\n",
    "low_df, DTandPRP_tok, clean4B = remove_DT_PRP(min_df, training_data_4)\n",
    "\n",
    "print(\"Rare words with low df = \", len(low_df), \"words. Examples:\", list(low_df)[:20])\n",
    "vocab_4B = set()\n",
    "for sent in clean4B:\n",
    "    for t in sent:\n",
    "        vocab_4B.add(t)\n",
    "print(\"Size of the rest vocab:\", len(vocab_4B))\n",
    "print(\"Samples:\", clean4B[10:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8e959f-6578-46b0-8ea4-6535ef86951d",
   "metadata": {},
   "source": [
    "## 4.2 Word-embedding model and training the classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbddd28b-c267-4d97-87e3-4730986673e4",
   "metadata": {},
   "source": [
    "(a) Encoding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a10698ca-a48c-4fa3-92e2-011c201be758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(training_labels_4+test_labels_4)\n",
    "print(list(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "888754b2-aabd-4efc-ad33-3eb27af00ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 2 5 5 4]\n",
      "['surprise', 'fear', 'surprise', 'surprise', 'sadness']\n",
      "['My duties?  All right.', \"No don't I beg of you!\", 'Really?!', 'But then who? The waitress I went out with last month?', 'You know? Forget it!']\n"
     ]
    }
   ],
   "source": [
    "training_classes = label_encoder.transform(training_labels_4)\n",
    "print(training_classes[:5])\n",
    "print(list(meld_dftrain['Emotion'])[:5])\n",
    "print(list(meld_dftrain['Utterance'])[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b930556e-7f9b-4083-9d64-7b401f123c8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "(b) Loading the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0161bbeb-21a3-4241-8805-e66d104dc0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-e0dd2b0edc29>:13: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  _ = glove2word2vec(glove_file, tmp_file)\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "from os import path\n",
    "\n",
    "wordembeddings=\"glove.twitter.27B.200d.txt\"\n",
    "glove_file = datapath(path.abspath('../glove/glove.twitter.27B.200d.txt'))\n",
    "\n",
    "# Create a word2vec model from the Glove text data\n",
    "tmp_file = get_tmpfile(\"test_word2vec.txt\")\n",
    "_ = glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "word_embedding_model = KeyedVectors.load_word2vec_format(tmp_file)\n",
    "\n",
    "# Dimensions set to 200.\n",
    "num_features = 200\n",
    "\n",
    "# Converting Index2Word\n",
    "index2word_set = set(word_embedding_model.index_to_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda92b8e-35dd-457f-a1be-71f72efb7895",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Filter A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "892d7d42-bd1b-4287-aaae-0c76ef32848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of our matrix is: (5279, 200)\n",
      "Review 0 of 5279\n",
      "Review 1000 of 5279\n",
      "Review 2000 of 5279\n",
      "Review 3000 of 5279\n",
      "Review 4000 of 5279\n",
      "Review 5000 of 5279\n"
     ]
    }
   ],
   "source": [
    "from utils import featureVecMethod, getAvgFeatureVecs\n",
    "\n",
    "trainFeatureVecs_4A, embedding_words_4A, no_embedding_words_4A = \\\n",
    "getAvgFeatureVecs(clean4A,\n",
    "                  word_embedding_model, \n",
    "                  index2word_set, \n",
    "                  num_features\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "649db7f7-65f6-4c0b-9b2d-95915ec15820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'all', 'right', 'no', 'of', 'really', 'but', 'then', 'who', 'waitress', 'go', 'out', 'with', 'last', 'month', 'know', 'forget', 'no', '-', 'no', '-', 'no', '-', 'no', 'no', 'who', 'who', 'talk', 'about', 'no', '-', '-', '-', 'actually', 'know', 'ever', 'say', 'they', 'close', 'down', 'bar', 'no', 'way', 'just', 'coffee', 'where', 'we', 'gon', 'na', 'hang']\n",
      "\n",
      "[' ', \"y'know\", '...', '...', ' ', ' ', ' ', \"y'know\", ' ', '15', '...', '...', '...', ' ', ' ', '...', ' ', ' ', ' ', \"i'm\", ' ', ' ', \"y'know\", ' ', ' ', ' ', ' ', '...', '  ', ' ', \"nothin'\", \"nothin'\", \"it's\", \"y'know\", '  ', '...', ' ', ' ', ' ', ' ', ' ', '  ', \"y'know\", '...', ' ', ' ', ' ', ' ', ' ', '...']\n"
     ]
    }
   ],
   "source": [
    "print(embedding_words_4A[:50])\n",
    "print()\n",
    "print(no_embedding_words_4A[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5c43afe-d127-4623-81f9-16b298bd1569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=LinearSVC(max_iter=2000), cv=10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "linear_model = svm.LinearSVC(max_iter=2000)\n",
    "svm_linear_clf_4A = CalibratedClassifierCV(linear_model , method='sigmoid', cv=10)\n",
    "\n",
    "svm_linear_clf_4A.fit(trainFeatureVecs_4A, training_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87cd4e8-f0b2-478e-9c86-9f3970061820",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Filter B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a32f6be2-c67f-4071-ad1d-88263065a6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of our matrix is: (5279, 200)\n",
      "Review 0 of 5279\n",
      "Review 1000 of 5279\n",
      "Review 2000 of 5279\n",
      "Review 3000 of 5279\n",
      "Review 4000 of 5279\n",
      "Review 5000 of 5279\n"
     ]
    }
   ],
   "source": [
    "trainFeatureVecs_4B, embedding_words_4B, no_embedding_words_4B = \\\n",
    "getAvgFeatureVecs(clean4B,\n",
    "                  word_embedding_model, \n",
    "                  index2word_set, \n",
    "                  num_features\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "003e7956-8227-4186-a875-aa87a4e235ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['?', 'all', 'right', '.', 'no', 'do', \"n't\", 'of', '!', 'really', '?', '!', 'but', 'then', 'who', '?', 'waitress', 'go', 'out', 'with', 'last', 'month', '?', 'know', '?', 'forget', '!', 'no', '-', '-', 'no', '-', 'no', ',', 'no', '!', 'who', ',', 'who', 'be', 'talk', 'about', '?', 'no', ',', 'i', '-', '-', 'i', '-']\n",
      "\n",
      "[' ', \"y'know\", '...', '...', ' ', ' ', ' ', \"y'know\", ' ', '15', '...', '...', '...', ' ', ' ', '...', ' ', ' ', ' ', \"i'm\", ' ', ' ', \"y'know\", ' ', ' ', ' ', ' ', '...', '  ', ' ', \"nothin'\", \"nothin'\", \"y'know\", '  ', '...', ' ', ' ', ' ', ' ', ' ', '  ', \"y'know\", '...', ' ', ' ', ' ', ' ', ' ', '...', 'goodacre']\n"
     ]
    }
   ],
   "source": [
    "print(embedding_words_4B[:50])\n",
    "print()\n",
    "print(no_embedding_words_4B[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c27c8747-5598-4bc9-9470-144e34d5b74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=LinearSVC(max_iter=2000), cv=10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = svm.LinearSVC(max_iter=2000)\n",
    "svm_linear_clf_4B = CalibratedClassifierCV(linear_model , method='sigmoid', cv=10)\n",
    "\n",
    "svm_linear_clf_4B.fit(trainFeatureVecs_4B, training_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4354c311-73ef-4a7b-847a-8fa19006dd7e",
   "metadata": {},
   "source": [
    "## 4.3 Predicting the test data and results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2683e951-d74f-4a02-b512-ce94c47c224e",
   "metadata": {},
   "source": [
    "Loading the systems and encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f469c20b-ecf6-4644-9644-e4e2d84b64c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 3 3 3]\n",
      "['surprise', 'anger', 'joy', 'joy', 'joy']\n",
      "[\"Why do all you're coffee mugs have numbers on the bottom?\", \"Oh. That's so Monica can keep track. That way if one on them is missing, she can be like, 'Where's number 27?!'\", 'Push!', \"Push 'em out, push 'em out, harder, harder.\", \"Push 'em out, push 'em out, way out!\"]\n"
     ]
    }
   ],
   "source": [
    "test_classes_4 = label_encoder.transform(test_labels_4)\n",
    "print(test_classes_4[:5])\n",
    "print(list(meld_dftest['Emotion'])[:5])\n",
    "print(list(meld_dftest['Utterance'])[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da5d2da-cc44-45de-abbe-83f209103b18",
   "metadata": {},
   "source": [
    "### Filter A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc67d7-ddd5-4aa0-8cab-c7fa7b4c62a8",
   "metadata": {},
   "source": [
    "(a) Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6a51ca46-cf3a-40d7-85e8-976f5ff67951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_df 2\n",
      "Max_df 135\n"
     ]
    }
   ],
   "source": [
    "max_df_test = len(test_data_4)//10\n",
    "\n",
    "low_df_test_4A, high_df_test_4A, test_mid_df_4A = \\\n",
    "low_high_mid_df(2, max_df_test, test_data_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7c36d430-ebb2-415d-ad51-34c379012d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a', 'and', 'be', 'to', 'the', 'i', ',', 'you', '.', '!', 'what', 'that', '?', 'do', 'it', \"n't\", 'oh'}\n"
     ]
    }
   ],
   "source": [
    "print(high_df_test_4A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2e92cd7c-bcb4-436c-be20-a8f24fb8a4cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of our matrix is: (1354, 200)\n",
      "Review 0 of 1354\n",
      "Review 1000 of 1354\n"
     ]
    }
   ],
   "source": [
    "testDataVecs_4A, test_4A_known_words, test_4A_unknown_words =\\\n",
    "getAvgFeatureVecs(test_mid_df_4A,\n",
    "                  word_embedding_model, \n",
    "                  index2word_set, \n",
    "                  num_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e6522eaf-1a74-4ac2-82d2-629f328b280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_4A = svm_linear_clf_4A.predict(testDataVecs_4A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fec3ee5-28e9-4410-92d0-7b2c9e76a16a",
   "metadata": {},
   "source": [
    "(b) Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2f990db4-ea96-4aad-83ff-08c120bf626f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'disgust' 'fear' 'joy' 'sadness' 'surprise']\n",
      "Embeddings SVM LINEAR: MELD, Filter A\n",
      "Word embedding model used glove.twitter.27B.200d.txt\n",
      "Word mininum document frequency: 2; maximum: 135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.426877  0.313043  0.361204       345\n",
      "           1   1.000000  0.014706  0.028986        68\n",
      "           2   0.666667  0.040000  0.075472        50\n",
      "           3   0.433333  0.808458  0.564236       402\n",
      "           4   0.380952  0.115385  0.177122       208\n",
      "           5   0.461268  0.466192  0.463717       281\n",
      "\n",
      "    accuracy                       0.436484      1354\n",
      "   macro avg   0.561516  0.292964  0.278456      1354\n",
      "weighted avg   0.466514  0.436484  0.387244      1354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Evaluating and analyzing the result\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report_4A = classification_report(test_classes_4,y_pred_svm_4A,digits = 6)\n",
    "print(label_encoder.classes_)\n",
    "print('Embeddings SVM LINEAR: MELD, Filter A')\n",
    "print('Word embedding model used', wordembeddings)\n",
    "print(f'Word mininum document frequency: {min_df}; maximum: {max_df_test}')\n",
    "print(report_4A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d0c5fc9a-8dcb-40ee-9f09-c750642d13c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix SVM, embeddings, MELD, Filter A\n",
      "['anger' 'disgust' 'fear' 'joy' 'sadness' 'surprise']\n",
      "[[108   0   0 154  13  70]\n",
      " [ 25   1   0  24   3  15]\n",
      " [ 11   0   2  26   5   6]\n",
      " [ 33   0   0 325   7  37]\n",
      " [ 49   0   0 110  24  25]\n",
      " [ 27   0   1 111  11 131]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print('Confusion matrix SVM, embeddings, MELD, Filter A')\n",
    "print(label_encoder.classes_)\n",
    "print(sklearn.metrics.confusion_matrix(test_classes_4,y_pred_svm_4A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7a3e2224-9ead-4af4-91a7-3df7c797cdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>Chat</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.974532</td>\n",
       "      <td>4.697510</td>\n",
       "      <td>1.819319</td>\n",
       "      <td>36.286647</td>\n",
       "      <td>9.914662</td>\n",
       "      <td>25.307331</td>\n",
       "      <td>Why do all you're coffee mugs have numbers on ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.044432</td>\n",
       "      <td>4.281091</td>\n",
       "      <td>4.068578</td>\n",
       "      <td>43.770453</td>\n",
       "      <td>12.257258</td>\n",
       "      <td>12.578188</td>\n",
       "      <td>Oh. That's so Monica can keep track. That way ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.557398</td>\n",
       "      <td>6.361188</td>\n",
       "      <td>16.760104</td>\n",
       "      <td>21.537180</td>\n",
       "      <td>5.397572</td>\n",
       "      <td>9.386557</td>\n",
       "      <td>Push!</td>\n",
       "      <td>anger</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.797333</td>\n",
       "      <td>4.415145</td>\n",
       "      <td>4.759714</td>\n",
       "      <td>35.455020</td>\n",
       "      <td>20.440459</td>\n",
       "      <td>5.132329</td>\n",
       "      <td>Push 'em out, push 'em out, harder, harder.</td>\n",
       "      <td>joy</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.587861</td>\n",
       "      <td>5.569622</td>\n",
       "      <td>6.130495</td>\n",
       "      <td>41.155173</td>\n",
       "      <td>13.071929</td>\n",
       "      <td>4.484920</td>\n",
       "      <td>Push 'em out, push 'em out, way out!</td>\n",
       "      <td>joy</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       anger   disgust       fear        joy    sadness   surprise  \\\n",
       "0  21.974532  4.697510   1.819319  36.286647   9.914662  25.307331   \n",
       "1  23.044432  4.281091   4.068578  43.770453  12.257258  12.578188   \n",
       "2  40.557398  6.361188  16.760104  21.537180   5.397572   9.386557   \n",
       "3  29.797333  4.415145   4.759714  35.455020  20.440459   5.132329   \n",
       "4  29.587861  5.569622   6.130495  41.155173  13.071929   4.484920   \n",
       "\n",
       "                                                Chat Prediction      Gold  \n",
       "0  Why do all you're coffee mugs have numbers on ...        joy  surprise  \n",
       "1  Oh. That's so Monica can keep track. That way ...        joy     anger  \n",
       "2                                              Push!      anger       joy  \n",
       "3        Push 'em out, push 'em out, harder, harder.        joy       joy  \n",
       "4               Push 'em out, push 'em out, way out!        joy       joy  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probabilities_4A = svm_linear_clf_4A.predict_proba(testDataVecs_4A)\n",
    "\n",
    "pred_labels_4A = []\n",
    "for predicted_label in y_pred_svm_4A:\n",
    "    pred_labels_4A.append(label_encoder.classes_[predicted_label])\n",
    "\n",
    "gold_labels_4A = []\n",
    "for gold_label in test_classes_4:\n",
    "    gold_labels_4A.append(label_encoder.classes_[gold_label])\n",
    "\n",
    "result_frame4A = pd.DataFrame(pred_probabilities_4A*100, columns=label_encoder.classes_)\n",
    "\n",
    "result_frame4A['Chat']= list(meld_dftest['Utterance'])\n",
    "result_frame4A['Prediction']=pred_labels_4A\n",
    "result_frame4A['Gold']=gold_labels_4A\n",
    "\n",
    "result_frame4A.to_csv(\"result_frame4A.csv\")\n",
    "result_frame4A.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04fc0ed-2cd8-45f1-bb50-af60f45675dd",
   "metadata": {},
   "source": [
    "### Filter B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "68d1cb97-7e56-4d85-ac38-eb16ef61c782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determiner and pronouns {'she', \"you're\", \"they're\", 'no', 'yours', 'his', \"i'm\", 'some', 'you', 'themselves', 'their', 'either', 'this', 'both', \"'em\", 'a', 'the', 'they', 'himself', 'that', 'â€™s', \"my'this\", 'those', \"'s\", 'mine', 'ya', 'each', 'myself', 'all', 'hers', 'i', 'its', 'her', 'your', 'my', \"i'i\", 'any', 'we', 'our', 'he', 'every', 'one', 'another', 'it', 'an', 'yourself', 'these'}\n",
      "Min_df 2\n"
     ]
    }
   ],
   "source": [
    "low_df_test_4B, DTandPRP_test_4B, clean_test_4B = \\\n",
    "remove_DT_PRP(2, test_data_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "99bf09bb-37f5-435e-90bd-61dc3da66314",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of our matrix is: (1354, 200)\n",
      "Review 0 of 1354\n",
      "Review 1000 of 1354\n"
     ]
    }
   ],
   "source": [
    "testDataVecs_4B, test_4B_known_words, test_4B_unknown_words =\\\n",
    "getAvgFeatureVecs(clean_test_4B,\n",
    "                  word_embedding_model, \n",
    "                  index2word_set, \n",
    "                  num_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c35737b0-1f2e-49ae-a724-2b4789d3a537",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_4B = svm_linear_clf_4B.predict(testDataVecs_4B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d87f51e7-8f80-430b-84b7-637c060a5fc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'disgust' 'fear' 'joy' 'sadness' 'surprise']\n",
      "Embeddings SVM LINEAR: MELD, Filter B\n",
      "Word embedding model used glove.twitter.27B.200d.txt\n",
      "Word mininum document frequency 2 ; DT PRP removed\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.458955  0.356522  0.401305       345\n",
      "           1   0.333333  0.029412  0.054054        68\n",
      "           2   0.300000  0.060000  0.100000        50\n",
      "           3   0.482036  0.800995  0.601869       402\n",
      "           4   0.526316  0.240385  0.330033       208\n",
      "           5   0.573290  0.626335  0.598639       281\n",
      "\n",
      "    accuracy                       0.499261      1354\n",
      "   macro avg   0.445655  0.352275  0.347650      1354\n",
      "weighted avg   0.487705  0.499261  0.462291      1354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_4B = classification_report(test_classes_4,y_pred_svm_4B,digits = 6)\n",
    "print(label_encoder.classes_)\n",
    "print('Embeddings SVM LINEAR: MELD, Filter B')\n",
    "print('Word embedding model used', wordembeddings)\n",
    "print('Word mininum document frequency', min_df, \"; DT PRP removed\")\n",
    "print(report_4B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "54d93a5d-5297-4303-9e06-db286738b5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix SVM, embeddings, MELD, Filter B\n",
      "['anger' 'disgust' 'fear' 'joy' 'sadness' 'surprise']\n",
      "[[123   2   2 136  16  66]\n",
      " [ 25   2   0  29   5   7]\n",
      " [ 10   0   3  21   6  10]\n",
      " [ 37   1   1 322  13  28]\n",
      " [ 46   1   2  89  50  20]\n",
      " [ 27   0   2  71   5 176]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion matrix SVM, embeddings, MELD, Filter B')\n",
    "print(label_encoder.classes_)\n",
    "print(sklearn.metrics.confusion_matrix(test_classes_4,y_pred_svm_4B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "df179255-5c99-4a92-83ed-61b97996af47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>Chat</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.467972</td>\n",
       "      <td>4.532039</td>\n",
       "      <td>2.018750</td>\n",
       "      <td>15.162789</td>\n",
       "      <td>8.827758</td>\n",
       "      <td>43.990691</td>\n",
       "      <td>Why do all you're coffee mugs have numbers on ...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.545227</td>\n",
       "      <td>4.368579</td>\n",
       "      <td>3.665200</td>\n",
       "      <td>46.422368</td>\n",
       "      <td>13.581513</td>\n",
       "      <td>12.417113</td>\n",
       "      <td>Oh. That's so Monica can keep track. That way ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.459969</td>\n",
       "      <td>3.640484</td>\n",
       "      <td>4.550625</td>\n",
       "      <td>29.936859</td>\n",
       "      <td>2.548967</td>\n",
       "      <td>5.863097</td>\n",
       "      <td>Push!</td>\n",
       "      <td>anger</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.274717</td>\n",
       "      <td>3.971997</td>\n",
       "      <td>6.440881</td>\n",
       "      <td>25.025715</td>\n",
       "      <td>29.345872</td>\n",
       "      <td>3.940817</td>\n",
       "      <td>Push 'em out, push 'em out, harder, harder.</td>\n",
       "      <td>anger</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.620567</td>\n",
       "      <td>4.945454</td>\n",
       "      <td>6.789892</td>\n",
       "      <td>27.679692</td>\n",
       "      <td>11.559821</td>\n",
       "      <td>5.404574</td>\n",
       "      <td>Push 'em out, push 'em out, way out!</td>\n",
       "      <td>anger</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       anger   disgust      fear        joy    sadness   surprise  \\\n",
       "0  25.467972  4.532039  2.018750  15.162789   8.827758  43.990691   \n",
       "1  19.545227  4.368579  3.665200  46.422368  13.581513  12.417113   \n",
       "2  53.459969  3.640484  4.550625  29.936859   2.548967   5.863097   \n",
       "3  31.274717  3.971997  6.440881  25.025715  29.345872   3.940817   \n",
       "4  43.620567  4.945454  6.789892  27.679692  11.559821   5.404574   \n",
       "\n",
       "                                                Chat Prediction      Gold  \n",
       "0  Why do all you're coffee mugs have numbers on ...   surprise  surprise  \n",
       "1  Oh. That's so Monica can keep track. That way ...        joy     anger  \n",
       "2                                              Push!      anger       joy  \n",
       "3        Push 'em out, push 'em out, harder, harder.      anger       joy  \n",
       "4               Push 'em out, push 'em out, way out!      anger       joy  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probabilities_4B = svm_linear_clf_4B.predict_proba(testDataVecs_4B)\n",
    "\n",
    "pred_labels_4B = []\n",
    "for predicted_label in y_pred_svm_4B:\n",
    "    pred_labels_4B.append(label_encoder.classes_[predicted_label])\n",
    "\n",
    "gold_labels_4B = []\n",
    "for gold_label in test_classes:\n",
    "    gold_labels_4B.append(label_encoder.classes_[gold_label])\n",
    "\n",
    "result_frame4B = pd.DataFrame(pred_probabilities_4B*100, columns=label_encoder.classes_)\n",
    "\n",
    "result_frame4B['Chat']= list(meld_dftest['Utterance'])\n",
    "result_frame4B['Prediction']=pred_labels_4B\n",
    "result_frame4B['Gold']=gold_labels_4B\n",
    "\n",
    "result_frame4B.to_csv(\"result_frame4B.csv\")\n",
    "result_frame4B.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
