{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c09547e-9a7d-4fb5-94ca-1e87df66694b",
   "metadata": {},
   "source": [
    "# 3. MELD+Tweets, BoW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edd1c61-f66c-460b-931d-6e807aa337bc",
   "metadata": {},
   "source": [
    "## 3.1 Data preparation and filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e247abb7-7266-4851-8a4a-44d1c3c5bf6d",
   "metadata": {},
   "source": [
    "(a) Loading the MELD data and dropping the 'Neutral' label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e780703b-be9c-49da-ad50-12676d3171d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-f4309fae7c64>:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  meld_dftrain['Utterance'] = meld_dftrain['Utterance'].str.replace(\"\\x92|\\x97|\\x91|\\x93|\\x94|\\x85\", \"'\")\n",
      "<ipython-input-1-f4309fae7c64>:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  meld_dftest['Utterance'] = meld_dftest['Utterance'].str.replace(\"\\x92|\\x97|\\x91|\\x93|\\x94|\\x85\", \"'\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filepath = './data/MELD/train_sent_emo.csv'\n",
    "meld_dftrain = pd.read_csv(filepath)\n",
    "meld_dftrain['Utterance'] = meld_dftrain['Utterance'].str.replace(\"\\x92|\\x97|\\x91|\\x93|\\x94|\\x85\", \"'\")\n",
    "\n",
    "filepath = './data/MELD/test_sent_emo.csv'\n",
    "meld_dftest = pd.read_csv(filepath)\n",
    "meld_dftest['Utterance'] = meld_dftest['Utterance'].str.replace(\"\\x92|\\x97|\\x91|\\x93|\\x94|\\x85\", \"'\")\n",
    "\n",
    "meld_dftrain = meld_dftrain.set_index(\"Emotion\", drop=False)\n",
    "meld_dftrain = meld_dftrain.drop(\"neutral\", axis=0)\n",
    "\n",
    "meld_dftest = meld_dftest.set_index(\"Emotion\", drop=False)\n",
    "meld_dftest = meld_dftest.drop(\"neutral\", axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dd19d1-c435-44ec-89a2-fe0ea422665b",
   "metadata": {},
   "source": [
    "(b) Loading the Tweets data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c7a0c11-8289-452b-a315-ccf06e14cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'data/wassa/training/all.train.tsv'\n",
    "tweets_dftrain = pd.read_csv(filepath, sep='\\t')\n",
    "\n",
    "filepath = 'data/wassa/testing/all.test.tsv'\n",
    "tweets_dftest = pd.read_csv(filepath, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970afbb5-cf02-48fd-83ea-ebc816b7f01f",
   "metadata": {
    "tags": []
   },
   "source": [
    "(c) Combining the two data sets\n",
    "  -  Rename the following axes the same names:\n",
    "      -  MELD  \"Sr No.\": \"ID\", \"Utterance\": \"Sent\"\n",
    "      -  Tweets  \"Tweet\": \"Sent\", \"Label\": \"Emotion\"\n",
    "  - Concatenate the two dataframes in a way that their IDs, sentences and labels are aligned. Two additional keys: \"MELD\" and \"Tweets\" are added to identify from where a particular entry is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bd964de-8ca1-4765-a38d-7014a356713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change index of MELD back to number sequence\n",
    "meld_dftrain = meld_dftrain.set_index(pd.Series(list(range(len(meld_dftrain)))))\n",
    "meld_dftest = meld_dftest.set_index(pd.Series(list(range(len(meld_dftest)))))\n",
    "\n",
    "# Training data\n",
    "meld_dftrain = meld_dftrain.rename(columns={\"Sr No.\": \"ID\", \"Utterance\": \"Sent\"})\n",
    "tweets_dftrain = tweets_dftrain.rename(columns={\"Tweet\": \"Sent\", \"Label\": \"Emotion\"})\n",
    "combined_dftrain = pd.concat([meld_dftrain, tweets_dftrain], keys=['MELD', 'Tweets'])\n",
    "\n",
    "# Test data\n",
    "meld_dftest = meld_dftest.rename(columns={\"Sr No.\": \"ID\", \"Utterance\": \"Sent\"})\n",
    "tweets_dftest = tweets_dftest.rename(columns={\"Tweet\": \"Sent\", \"Label\": \"Emotion\"})\n",
    "combined_dftest = pd.concat([meld_dftest, tweets_dftest], keys=['MELD', 'Tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94f61977-3932-480f-8f85-35b369eb0310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sent</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>surprise</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:34,452</td>\n",
       "      <td>00:16:40,917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>No don't I beg of you!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>fear</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:17:02,856</td>\n",
       "      <td>00:17:04,858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>Really?!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>surprise</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:17:13,491</td>\n",
       "      <td>00:17:16,536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>But then who? The waitress I went out with las...</td>\n",
       "      <td>Joey</td>\n",
       "      <td>surprise</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>00:36:40,364</td>\n",
       "      <td>00:36:42,824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>You know? Forget it!</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>sadness</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>00:36:44,368</td>\n",
       "      <td>00:36:46,578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               Sent   Speaker   Emotion  \\\n",
       "0   5                             My duties?  All right.  Chandler  surprise   \n",
       "1  11                             No don't I beg of you!  Chandler      fear   \n",
       "2  13                                           Really?!  Chandler  surprise   \n",
       "3  15  But then who? The waitress I went out with las...      Joey  surprise   \n",
       "4  16                               You know? Forget it!    Rachel   sadness   \n",
       "\n",
       "  Sentiment  Dialogue_ID  Utterance_ID  Season  Episode     StartTime  \\\n",
       "0  positive            0             4       8       21  00:16:34,452   \n",
       "1  negative            0            10       8       21  00:17:02,856   \n",
       "2  positive            0            12       8       21  00:17:13,491   \n",
       "3  negative            1             0       9       23  00:36:40,364   \n",
       "4  negative            1             1       9       23  00:36:44,368   \n",
       "\n",
       "        EndTime  \n",
       "0  00:16:40,917  \n",
       "1  00:17:04,858  \n",
       "2  00:17:16,536  \n",
       "3  00:36:42,824  \n",
       "4  00:36:46,578  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the changes\n",
    "meld_dftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44e3d5b1-3367-48cb-a9e1-58b03e8f6faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sent</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                               Sent Emotion  Score\n",
       "0  10000  How the fu*k! Who the heck! moved my fridge!.....   anger  0.938\n",
       "1  10001  So my Indian Uber driver just called someone t...   anger  0.896\n",
       "2  10002  @DPD_UK I asked for my parcel to be delivered ...   anger  0.896\n",
       "3  10003  so ef whichever butt wipe pulled the fire alar...   anger  0.896\n",
       "4  10004  Don't join @BTCare they put the phone down on ...   anger  0.896"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_dftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42f3f011-c818-4dc1-952f-9bef168e5177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sent</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">MELD</th>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>surprise</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>00:16:34,452</td>\n",
       "      <td>00:16:40,917</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>No don't I beg of you!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>fear</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>00:17:02,856</td>\n",
       "      <td>00:17:04,858</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>Really?!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>surprise</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>00:17:13,491</td>\n",
       "      <td>00:17:16,536</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>But then who? The waitress I went out with las...</td>\n",
       "      <td>Joey</td>\n",
       "      <td>surprise</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>00:36:40,364</td>\n",
       "      <td>00:36:42,824</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>You know? Forget it!</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>sadness</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>00:36:44,368</td>\n",
       "      <td>00:36:46,578</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               Sent   Speaker  \\\n",
       "MELD 0   5                             My duties?  All right.  Chandler   \n",
       "     1  11                             No don't I beg of you!  Chandler   \n",
       "     2  13                                           Really?!  Chandler   \n",
       "     3  15  But then who? The waitress I went out with las...      Joey   \n",
       "     4  16                               You know? Forget it!    Rachel   \n",
       "\n",
       "         Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n",
       "MELD 0  surprise  positive          0.0           4.0     8.0     21.0   \n",
       "     1      fear  negative          0.0          10.0     8.0     21.0   \n",
       "     2  surprise  positive          0.0          12.0     8.0     21.0   \n",
       "     3  surprise  negative          1.0           0.0     9.0     23.0   \n",
       "     4   sadness  negative          1.0           1.0     9.0     23.0   \n",
       "\n",
       "           StartTime       EndTime  Score  \n",
       "MELD 0  00:16:34,452  00:16:40,917    NaN  \n",
       "     1  00:17:02,856  00:17:04,858    NaN  \n",
       "     2  00:17:13,491  00:17:16,536    NaN  \n",
       "     3  00:36:40,364  00:36:42,824    NaN  \n",
       "     4  00:36:44,368  00:36:46,578    NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7a7783d-ea21-4710-b0ec-17576238963d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sent</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Tweets</th>\n",
       "      <th>3608</th>\n",
       "      <td>40781</td>\n",
       "      <td>@VivienLloyd Thank you so much! Just home - st...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sadness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3609</th>\n",
       "      <td>40782</td>\n",
       "      <td>Just put the winter duvet on ☃️❄️🌬☔️</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sadness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3610</th>\n",
       "      <td>40783</td>\n",
       "      <td>@SilkInSide @TommyJoeRatliff that's so pretty!...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sadness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>40784</td>\n",
       "      <td>@BluesfestByron second artist announcement loo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sadness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>40785</td>\n",
       "      <td>I can literally eat creamy pesto pasta topped ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sadness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID                                               Sent Speaker  \\\n",
       "Tweets 3608  40781  @VivienLloyd Thank you so much! Just home - st...     NaN   \n",
       "       3609  40782              Just put the winter duvet on ☃️❄️🌬☔️      NaN   \n",
       "       3610  40783  @SilkInSide @TommyJoeRatliff that's so pretty!...     NaN   \n",
       "       3611  40784  @BluesfestByron second artist announcement loo...     NaN   \n",
       "       3612  40785  I can literally eat creamy pesto pasta topped ...     NaN   \n",
       "\n",
       "             Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n",
       "Tweets 3608  sadness       NaN          NaN           NaN     NaN      NaN   \n",
       "       3609  sadness       NaN          NaN           NaN     NaN      NaN   \n",
       "       3610  sadness       NaN          NaN           NaN     NaN      NaN   \n",
       "       3611  sadness       NaN          NaN           NaN     NaN      NaN   \n",
       "       3612  sadness       NaN          NaN           NaN     NaN      NaN   \n",
       "\n",
       "            StartTime EndTime  Score  \n",
       "Tweets 3608       NaN     NaN  0.104  \n",
       "       3609       NaN     NaN  0.104  \n",
       "       3610       NaN     NaN  0.088  \n",
       "       3611       NaN     NaN  0.083  \n",
       "       3612       NaN     NaN  0.083  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dftrain.tail()\n",
    "\n",
    "# The data sets are concatenated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba49719-fffb-48d7-a8df-7f28acbee7b0",
   "metadata": {},
   "source": [
    "(d) Tokenizing and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe6eea66-fc87-450c-96d6-afc44f8004fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Using spaCy to tokenize the sentences\n",
    "training_data_3 = [nlp(sent) for sent in list(combined_dftrain['Sent'])]\n",
    "training_labels_3 = list(combined_dftrain['Emotion'])\n",
    "\n",
    "test_data_3 = [nlp(sent) for sent in list(combined_dftest['Sent'])]\n",
    "test_labels_3 = list(combined_dftest['Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da34b922-7685-48e7-b745-17a88cc17995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sent in training_data_1:\n",
    "#     for token in sent:\n",
    "#         if \"I'm\" == token.text:\n",
    "#             print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b91bab-11ae-4540-8542-43c01b7d6d32",
   "metadata": {},
   "source": [
    "    (i) Filter A: MaxDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f367242c-6231-411a-993d-2ec6bbd9f456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_df 2\n",
      "Max_df 889\n",
      "Rare words with low df =  5972 words. Examples:  ['lolololol', '@fireemblemlord', '@childrensissue', 'witout', 'lookd', '@gopro', 'unconsciously', 'gaze', 'netizen', 'hey!-hey', 'quotient', '@hunterhaye', 'laudrup', 'lakeside', 'crisis', 'shrill', 'lousy', 'charity', 'momentarily', 'fighting']\n",
      "Stop words with high df: {'do', 'you', 'have', 'i', '.', 'be', 'a', '?', 'to', 'it', \"n't\", 'and', ',', '!', 'the', 'that', '#', 'my', 'of'}\n",
      "Size of the rest vocab: 4915\n",
      "Samples: [['hey', 'ross', 'would', 'great', 'if', 'we', 'could', 'go', 'two', 'straight', 'hour', 'without', 'drop'], ['okay'], ['uh', '-', 'oh']]\n"
     ]
    }
   ],
   "source": [
    "from utils import low_high_mid_df\n",
    "\n",
    "min_df = 2\n",
    "max_df = len(training_data_3)//10\n",
    "\n",
    "low_df, high_df, clean3A = low_high_mid_df(min_df, max_df, training_data_3)\n",
    "\n",
    "print(\"Rare words with low df = \", len(low_df), \"words. Examples: \", list(low_df)[:20])\n",
    "print(\"Stop words with high df:\", high_df)\n",
    "vocab_3A = set()\n",
    "for sent in clean3A:\n",
    "    for t in sent:\n",
    "        vocab_3A.add(t)\n",
    "print(\"Size of the rest vocab:\", len(vocab_3A))\n",
    "print(\"Samples:\", clean3A[100:103])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a43f3b-82f0-4a4b-8808-ce355f558703",
   "metadata": {},
   "source": [
    "    (ii) Filter B: DTandPRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e8e347d-a24f-47e5-bcf3-bdf3577a7cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determiner and pronouns {'bridgetjonesbaby', 'no', \"it's\", 'i', '@snub23', \"i'm\", '@ryyyshh', 'tbh', 'tux', 'em', 'ba', 'hbu', 'strength.\\\\nthey', 'himself', 'every', '\\\\n\\\\nsam', 'this', \"i'y'know\", 'myself', 'jut', 'ours', 'your', 'yourself', '👅', 'oldham\\\\nnext', \"up'i\", '🍁', '@blackeyed_susie', '✨', 'itself', '#', \"i'i'm\", 'ty', 'you', '@british_airways', '@relaqss', 'ourselves', \"'s\", 'its', \"you're'you\", 'xx', \"mean'i\", 'an', 'don’t', \"you're\", '@mhchat', '’s', 'any', 'one', 'those', 'each', '😡', '\\\\nit', 'd', 'the-', 'themselves', 'his', '@its.finfin', '@m_t_f_72', '\\uf62b', '@fra93_bruno', \"i'll\", \"that'you\", 'my', 'they', 'ya', 'yours', '@neyaphemmaster', '\\\\n\\\\nother', 'also-', 'another', \"was'the\", '😧', 'eagles.\\\\nthey', 'tho', 'ek', \"y'\", 'it', 'scarred,\\\\nthis', 'near,\\\\nthe', 'n', 'her', 'the', 'y', \"fact'yes\", '@kevincanwaitcbs', \"underwear'you\", '🐮', 'their', 'memphis', '@themathofyou', '@weebtard', \"film'that\", 'she', '_', '@sargon_of_akkad', 'either', 'we', 'some', '@smshow', 'these', '❤', 'all', 'a', 'he', 'isthereahelplineforthis', '@rowillfindyou', '@reyesaverie', ':)', 'that?s', '🐈', 'hers', 'u', '😊', '@missmeliss465', \"'em\", '@melissajoyrd', '\\\\n#you', '\\\\nimagine', 'herself', 'our', 'i-', 'that', 'thy', 'both', '@ntfc', 'mine', '@adsbyflaherty', 'neither'}\n",
      "Min_df 2\n",
      "Rare words with low df =  5939 words. Examples: ['lolololol', '@fireemblemlord', '@childrensissue', 'witout', 'lookd', '@gopro', 'unconsciously', 'gaze', 'netizen', 'hey!-hey', 'quotient', '@hunterhaye', 'laudrup', 'lakeside', 'crisis', 'shrill', 'lousy', 'charity', 'momentarily', 'fighting']\n",
      "Size of the rest vocab: 4887\n",
      "Samples: [['hey', 'ross', ',', 'would', \"n't\", 'be', 'great', 'if', 'could', 'go', 'two', 'straight', 'hour', 'without', 'drop', '?', '!'], ['okay', '!'], ['uh', '-', 'oh', '.'], ['have', 'to', 'pee', '.', 'and', 'rachel', 'be', 'in', 'bathroom', '!'], ['man', ',', 'do', \"n't\", 'think', 'be', 'gon', 'na', 'make', '!']]\n"
     ]
    }
   ],
   "source": [
    "from utils import remove_DT_PRP\n",
    "\n",
    "min_df = 2\n",
    "\n",
    "low_df, DTandPRP_tok, clean3B = remove_DT_PRP(min_df, training_data_3)\n",
    "\n",
    "print(\"Rare words with low df = \", len(low_df), \"words. Examples:\", list(low_df)[:20])\n",
    "vocab_3B = set()\n",
    "for sent in clean3B:\n",
    "    for t in sent:\n",
    "        vocab_3B.add(t)\n",
    "print(\"Size of the rest vocab:\", len(vocab_3B))\n",
    "print(\"Samples:\", clean3B[100:105])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5503dcd-051f-456c-8c06-242dc3936abb",
   "metadata": {},
   "source": [
    "## 3.2 BoW vectorization and training the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98847da8-1120-4517-8908-39c1944c68b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f462c6-2441-453b-ba1d-ab4c3625dd4e",
   "metadata": {},
   "source": [
    "(a) Encoding training labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48136334-9fc4-46d2-b1b4-be32e57d605f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(training_labels_3+test_labels_3)\n",
    "print(list(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62779ff8-6835-416f-8838-108b83cf6dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 2 5 5 4]\n",
      "['surprise', 'fear', 'surprise', 'surprise', 'sadness']\n",
      "['My duties?  All right.', \"No don't I beg of you!\", 'Really?!', 'But then who? The waitress I went out with last month?', 'You know? Forget it!']\n"
     ]
    }
   ],
   "source": [
    "training_classes = label_encoder.transform(training_labels_3)\n",
    "print(training_classes[:5])\n",
    "print(list(combined_dftrain['Emotion'])[:5])\n",
    "print(list(combined_dftrain['Sent'])[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a55ac9e-a8d7-4c54-89cb-4210170a94cb",
   "metadata": {},
   "source": [
    "### Filter A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448d503f-ba83-4f94-9f89-d7d47f061500",
   "metadata": {},
   "source": [
    "(a) Vectorise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47f37672-b95f-4b50-ad7b-b24fc8ec1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A CountVectorizer which takes tokenized lists as input\n",
    "### Taken from https://stackoverflow.com/questions/35867484/pass-tokens-to-countvectorizer,\n",
    "### https://stackoverflow.com/questions/27673527/how-should-i-vectorize-the-following-list-of-lists-with-scikit-learn, 26 Oct 2021\n",
    "\n",
    "def dummy(x):\n",
    "    return x\n",
    "\n",
    "utterance_vec_3A = CountVectorizer(tokenizer=dummy, lowercase=False)\n",
    "\n",
    "training_count_vectors_3A = utterance_vec_3A.fit_transform(clean3A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc898b49-b088-4d36-bf33-4e76cb2711d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(training_count_vectors_3A .toarray()[0][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48c15e0d-73ce-49b7-94b9-1ad6e5180fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4915\n"
     ]
    }
   ],
   "source": [
    "#Total number of word features or the length of the total vector\n",
    "print(len(utterance_vec_3A.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "216a60ec-b42f-4ab2-9489-14cba72e689f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '  ', '   ', '\"', '#funny', '#whatever', '$', '%', '&', \"'\", \"'\\\\n\\\\nhe\", \"'cause\", \"'d\", \"'em\", \"'everywhere\", \"'i\", \"'ll\", \"'s\", \"'ve\", '(', ')', '):', '*', '+', '-', '--', '-2.5', '-dalai', '-terrible-', '..', '...', '....', '.....', '......', '.......', '..........', '.@divamagazine', '.@simonnricketts', '.@tolumanda', '/', '0', '1', '1,000', '1/2', '10', '10/11', '100', '1000', '100k', '101']\n"
     ]
    }
   ],
   "source": [
    "# First 50 feature names\n",
    "print(list(utterance_vec_3A.get_feature_names())[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9f5e12c-8c97-4596-8b32-b9bd7cbd1b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert raw frequency counts into TF-IDF values\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "training_tfidf_3A = tfidf_transformer.fit_transform(training_count_vectors_3A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8b88474-444a-492c-9f4c-da5f4379221d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49906941 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(training_tfidf_3A.toarray()[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96903b2b-b969-4e1a-9ed1-03507616e648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=LinearSVC(max_iter=2000), cv=10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "linear_model = svm.LinearSVC(max_iter=2000)\n",
    "svm_linear_clf_3A = CalibratedClassifierCV(linear_model , method='sigmoid', cv=10)\n",
    "\n",
    "svm_linear_clf_3A.fit(training_tfidf_3A, training_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a142e14-9ebe-4d66-944e-addc4eafbfeb",
   "metadata": {},
   "source": [
    "### Filter B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cd335d-3faa-47bf-85d9-7f8e00df61e9",
   "metadata": {},
   "source": [
    "(a) Vectorise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b77f2d46-1103-409f-9ebe-00368c7b589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "utterance_vec_3B = CountVectorizer(tokenizer=dummy, lowercase=False)\n",
    "\n",
    "training_count_vectors_3B = utterance_vec_3B.fit_transform(clean3B)\n",
    "training_tfidf_3B = tfidf_transformer.fit_transform(training_count_vectors_3B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f2f7511-9811-4f96-9014-6058acca3a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4887\n"
     ]
    }
   ],
   "source": [
    "#Total number of word features or the length of the total vector\n",
    "print(len(utterance_vec_3B.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf812ed1-8047-47bc-92c7-735adcbec91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '  ', '   ', '!', '\"', '#', '#funny', '#whatever', '$', '%', '&', \"'\", \"'\\\\n\\\\nhe\", \"'cause\", \"'d\", \"'everywhere\", \"'i\", \"'ll\", \"'s\", \"'ve\", '(', ')', '):', '*', '+', ',', '-', '--', '-2.5', '-dalai', '-terrible-', '.', '..', '...', '....', '.....', '......', '.......', '..........', '.@divamagazine', '.@simonnricketts', '.@tolumanda', '/', '0', '1', '1,000', '1/2', '10', '10/11', '100']\n"
     ]
    }
   ],
   "source": [
    "# First 50 feature names\n",
    "print(list(utterance_vec_3B.get_feature_names())[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001ea6e4-7962-4024-9a90-a0faeed5e730",
   "metadata": {},
   "source": [
    "(b) Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd6d36be-6001-4d01-a8a3-2864c686dece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=LinearSVC(max_iter=2000), cv=10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = svm.LinearSVC(max_iter=2000)\n",
    "svm_linear_clf_3B = CalibratedClassifierCV(linear_model , method='sigmoid', cv=10)\n",
    "\n",
    "svm_linear_clf_3B.fit(training_tfidf_3B, training_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1bd11e-6826-4dbe-aedc-41c43bd7d6e1",
   "metadata": {},
   "source": [
    "## 3.3 Predicting the test data and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "baaa8b7e-e62b-429a-9991-c2afec624f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2646a9e2-5568-4801-934d-2582f38ea306",
   "metadata": {},
   "source": [
    "Encode the test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ccc6f43a-505d-4ccb-a298-42fc21361648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 3 3 3 3 3 3 3 4 5 0 0 0 3 3 2 0 1 5]\n",
      "['surprise', 'anger', 'joy', 'joy', 'joy']\n",
      "[\"Why do all you're coffee mugs have numbers on the bottom?\", \"Oh. That's so Monica can keep track. That way if one on them is missing, she can be like, 'Where's number 27?!'\", 'Push!', \"Push 'em out, push 'em out, harder, harder.\", \"Push 'em out, push 'em out, way out!\"]\n"
     ]
    }
   ],
   "source": [
    "test_classes = label_encoder.transform(test_labels_3)\n",
    "print(test_classes[:20])\n",
    "print(list(combined_dftest['Emotion'])[:5])\n",
    "print(list(combined_dftest['Sent'])[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a547d4-e641-4de4-a4de-b9e792c339e2",
   "metadata": {},
   "source": [
    "### Filter A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c2325e2-cbb8-4203-a8d1-82170e549670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_df 2\n",
      "Max_df 449\n"
     ]
    }
   ],
   "source": [
    "max_df_test = len(test_data_3)//10\n",
    "\n",
    "low_df_test_3A, high_df_test_3A, test_mid_df_3A = \\\n",
    "low_high_mid_df(2, max_df_test, test_data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f325163-4e4f-4d40-93c8-842b5670ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_count_3A = utterance_vec_3A.transform(test_mid_df_3A)\n",
    "test_tfidf_3A = tfidf_transformer.fit_transform(test_count_3A)\n",
    "\n",
    "y_pred_svm_3A = svm_linear_clf_3A.predict(test_tfidf_3A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48c3259d-d9e0-491b-b758-718c4a8b9a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'disgust' 'fear' 'joy' 'sadness' 'surprise']\n",
      "BoW TFIDF SVM LINEAR: MELD+Tweets, Filter A\n",
      "Word mininum document frequency 2 ; max: 449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.697248  0.619005  0.655801      1105\n",
      "           1   0.333333  0.014706  0.028169        68\n",
      "           2   0.812780  0.693780  0.748580      1045\n",
      "           3   0.608754  0.810036  0.695117      1116\n",
      "           4   0.694724  0.627696  0.659511       881\n",
      "           5   0.433628  0.523132  0.474194       281\n",
      "\n",
      "    accuracy                       0.670374      4496\n",
      "   macro avg   0.596745  0.548059  0.543562      4496\n",
      "weighted avg   0.679660  0.670374  0.667008      4496\n",
      "\n",
      "Confusion matrix SVM, BoW MELD+Tweets, Filter A\n",
      "['anger' 'disgust' 'fear' 'joy' 'sadness' 'surprise']\n",
      "[[684   1  56 213  87  64]\n",
      " [ 22   1   2  23   5  15]\n",
      " [ 72   1 725 125  92  30]\n",
      " [ 71   0  47 904  47  47]\n",
      " [100   0  52 140 553  36]\n",
      " [ 32   0  10  80  12 147]]\n"
     ]
    }
   ],
   "source": [
    "report3A = classification_report(test_classes,y_pred_svm_3A,digits = 6)\n",
    "print(label_encoder.classes_)\n",
    "print('BoW TFIDF SVM LINEAR: MELD+Tweets, Filter A')\n",
    "print('Word mininum document frequency', min_df, \"; max:\", max_df_test)\n",
    "print(report3A)\n",
    "\n",
    "print('Confusion matrix SVM, BoW MELD+Tweets, Filter A')\n",
    "print(label_encoder.classes_)\n",
    "print(sklearn.metrics.confusion_matrix(test_classes,y_pred_svm_3A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d6dfac1-fa22-4750-821b-2828107a92dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>Chat</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.552957</td>\n",
       "      <td>5.227196</td>\n",
       "      <td>23.327851</td>\n",
       "      <td>17.448887</td>\n",
       "      <td>17.569593</td>\n",
       "      <td>28.873515</td>\n",
       "      <td>Why do all you're coffee mugs have numbers on ...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.510428</td>\n",
       "      <td>2.168840</td>\n",
       "      <td>13.283216</td>\n",
       "      <td>45.837272</td>\n",
       "      <td>20.615817</td>\n",
       "      <td>3.584428</td>\n",
       "      <td>Oh. That's so Monica can keep track. That way ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.853089</td>\n",
       "      <td>3.108969</td>\n",
       "      <td>5.722333</td>\n",
       "      <td>9.683424</td>\n",
       "      <td>43.172987</td>\n",
       "      <td>11.459197</td>\n",
       "      <td>Push!</td>\n",
       "      <td>sadness</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.164984</td>\n",
       "      <td>5.033923</td>\n",
       "      <td>3.576142</td>\n",
       "      <td>17.268503</td>\n",
       "      <td>54.412347</td>\n",
       "      <td>2.544101</td>\n",
       "      <td>Push 'em out, push 'em out, harder, harder.</td>\n",
       "      <td>sadness</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.564224</td>\n",
       "      <td>5.020865</td>\n",
       "      <td>4.587863</td>\n",
       "      <td>28.055049</td>\n",
       "      <td>27.917534</td>\n",
       "      <td>9.854465</td>\n",
       "      <td>Push 'em out, push 'em out, way out!</td>\n",
       "      <td>joy</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       anger   disgust       fear        joy    sadness   surprise  \\\n",
       "0   7.552957  5.227196  23.327851  17.448887  17.569593  28.873515   \n",
       "1  14.510428  2.168840  13.283216  45.837272  20.615817   3.584428   \n",
       "2  26.853089  3.108969   5.722333   9.683424  43.172987  11.459197   \n",
       "3  17.164984  5.033923   3.576142  17.268503  54.412347   2.544101   \n",
       "4  24.564224  5.020865   4.587863  28.055049  27.917534   9.854465   \n",
       "\n",
       "                                                Chat Prediction      Gold  \n",
       "0  Why do all you're coffee mugs have numbers on ...   surprise  surprise  \n",
       "1  Oh. That's so Monica can keep track. That way ...        joy     anger  \n",
       "2                                              Push!    sadness       joy  \n",
       "3        Push 'em out, push 'em out, harder, harder.    sadness       joy  \n",
       "4               Push 'em out, push 'em out, way out!        joy       joy  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probabilities_3A = svm_linear_clf_3A.predict_proba(test_tfidf_3A)\n",
    "\n",
    "pred_labels_3A = []\n",
    "for predicted_label in y_pred_svm_3A:\n",
    "    pred_labels_3A.append(label_encoder.classes_[predicted_label])\n",
    "\n",
    "gold_labels_3A = []\n",
    "for gold_label in test_classes:\n",
    "    gold_labels_3A.append(label_encoder.classes_[gold_label])\n",
    "\n",
    "result_frame3A = pd.DataFrame(pred_probabilities_3A*100, columns=label_encoder.classes_)\n",
    "\n",
    "result_frame3A['Chat']= list(combined_dftest['Sent'])\n",
    "result_frame3A['Prediction']=pred_labels_3A\n",
    "result_frame3A['Gold']=gold_labels_3A\n",
    "\n",
    "result_frame3A.to_csv(\"result_frame3A.csv\")\n",
    "result_frame3A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "558f5351-85b1-431d-9788-4ee0f4ea5780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important features per emotion: 3A\n",
      "Important words in anger utterances\n",
      "anger 3.6500079099561296 anger\n",
      "anger 3.6415085332939965 rage\n",
      "anger 3.4825419087377254 angry\n",
      "anger 3.445447920127659 offend\n",
      "anger 3.136321475267664 bitter\n",
      "anger 2.933377672989411 fury\n",
      "anger 2.923266443202013 revenge\n",
      "anger 2.8706648768318184 offense\n",
      "anger 2.8041745428527336 fume\n",
      "anger 2.7846500212780403 burst\n",
      "anger 2.6243876260005665 furious\n",
      "anger 2.6138535976487836 wrath\n",
      "anger 2.6059136669177465 madden\n",
      "anger 2.576526635745796 rabid\n",
      "anger 2.5637964000920155 resent\n",
      "anger 2.490842286268994 outrage\n",
      "anger 2.482362431406309 irritate\n",
      "anger 2.451210075508196 snap\n",
      "anger 2.449743090030281 relentless\n",
      "anger 2.4422051384880628 insult\n",
      "-----------------------------------------\n",
      "Important words in disgust utterances\n",
      "disgust 1.800699329624385 disgusting\n",
      "disgust 1.7185263751602124 violate\n",
      "disgust 1.6831454546496154 eww\n",
      "disgust 1.6328923104597837 ew\n",
      "disgust 1.5755829685543976 behave\n",
      "disgust 1.513616158771912 clinic\n",
      "disgust 1.5071838013710737 boat\n",
      "disgust 1.463136192787657 drug\n",
      "disgust 1.3560385658155971 ugh\n",
      "disgust 1.302856594140285 shame\n",
      "disgust 1.2860721150789336 pig\n",
      "disgust 1.2547373534203465 smell\n",
      "disgust 1.2508712141556346 mindy\n",
      "disgust 1.1808947750275478 gross\n",
      "disgust 1.177543250400398 hairy\n",
      "disgust 1.1604221866541162 hate\n",
      "disgust 1.1536579920855858 toilet\n",
      "disgust 1.150278133408884 officially\n",
      "disgust 1.1323007371400107 o\n",
      "disgust 1.1312384473808819 buck\n",
      "-----------------------------------------\n",
      "Important words in fear utterances\n",
      "fear 3.795317395359601 terrorism\n",
      "fear 3.60346643052249 horror\n",
      "fear 3.304634535849266 bully\n",
      "fear 3.3044498240173494 terror\n",
      "fear 3.2984319913805225 nightmare\n",
      "fear 3.2820598254493283 fear\n",
      "fear 3.214039679489897 shake\n",
      "fear 3.1071804157000216 awe\n",
      "fear 3.025668199887623 shy\n",
      "fear 2.805836046030607 panic\n",
      "fear 2.6185711254931343 afraid\n",
      "fear 2.5469951297508304 nervous\n",
      "fear 2.5331510719927803 concern\n",
      "fear 2.4938092555214713 intimidate\n",
      "fear 2.4931756987949933 dread\n",
      "fear 2.482045263502302 horrific\n",
      "fear 2.2994510121173897 shocking\n",
      "fear 2.2921091186849245 horrible\n",
      "fear 2.24922692129127 awful\n",
      "fear 2.242169107096291 alarm\n",
      "-----------------------------------------\n",
      "Important words in joy utterances\n",
      "joy 3.331912224062683 playful\n",
      "joy 3.3270113204047838 glee\n",
      "joy 3.176064400154052 elated\n",
      "joy 3.144944924041007 hilarious\n",
      "joy 3.1193439791081032 cheer\n",
      "joy 3.075588230330695 rejoice\n",
      "joy 2.9834338096644037 joyous\n",
      "joy 2.709358677204754 optimism\n",
      "joy 2.6901908281806333 lively\n",
      "joy 2.6273282641151603 cheerfully\n",
      "joy 2.5605774313837655 exhilarate\n",
      "joy 2.5036063784999008 animate\n",
      "joy 2.4895327689993594 heyday\n",
      "joy 2.4316930767324534 laughter\n",
      "joy 2.4240746185410074 cheerful\n",
      "joy 2.417060516907452 hearty\n",
      "joy 2.4155654114375715 smile\n",
      "joy 2.396101984748968 delight\n",
      "joy 2.3953303465117397 joyful\n",
      "joy 2.3666036510885493 cheery\n",
      "-----------------------------------------\n",
      "Important words in sadness utterances\n",
      "sadness 3.6744927640884755 unhappy\n",
      "sadness 3.422989239581568 depressing\n",
      "sadness 3.3774676526379963 grim\n",
      "sadness 3.3617703003719925 sober\n",
      "sadness 3.253738955312999 dark\n",
      "sadness 3.1946883853211316 pine\n",
      "sadness 3.1362960335573926 depression\n",
      "sadness 3.1352797494413 depress\n",
      "sadness 3.06624642425885 blue\n",
      "sadness 2.89347701753609 pessimist\n",
      "sadness 2.8608711764363965 discourage\n",
      "sadness 2.734284503245798 dull\n",
      "sadness 2.7206803174204692 sad\n",
      "sadness 2.7193931354135277 gloomy\n",
      "sadness 2.712756738762047 sadly\n",
      "sadness 2.68826847302186 weary\n",
      "sadness 2.6584625822996863 sink\n",
      "sadness 2.584574980804585 sadness\n",
      "sadness 2.5724524953839403 gloom\n",
      "sadness 2.5660810991114897 mourn\n",
      "-----------------------------------------\n",
      "Important words in surprise utterances\n",
      "surprise 1.8255568850989774 wow\n",
      "surprise 1.6240892791181394 oww\n",
      "surprise 1.6231716020142621 julio\n",
      "surprise 1.5894132907342113 dancer\n",
      "surprise 1.5631872693457063 whoa\n",
      "surprise 1.5132080314184404 dress\n",
      "surprise 1.4826042558523156 fool\n",
      "surprise 1.4450361496560353 wha\n",
      "surprise 1.430270859762203 what\n",
      "surprise 1.373164327944051 believe\n",
      "surprise 1.3639835710170123 size\n",
      "surprise 1.341328662982171 forty\n",
      "surprise 1.3403246284542774 why\n",
      "surprise 1.3232182239713728 contraction\n",
      "surprise 1.3034036279822314 really\n",
      "surprise 1.2609078984109652 gosh\n",
      "surprise 1.2414855285308644 yike\n",
      "surprise 1.1821880812223946 nurse\n",
      "surprise 1.176408660896262 chuck\n",
      "surprise 1.1764017333763184 naked\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def average_importances(model):\n",
    "    coef_avg = 0\n",
    "    for classifier in model.calibrated_classifiers_:\n",
    "        coef_avg = coef_avg + classifier.base_estimator.coef_\n",
    "        \n",
    "    coef_avg  = coef_avg/len(model.calibrated_classifiers_)\n",
    "    return coef_avg\n",
    "\n",
    "def f_importances(importances, names, n=20):\n",
    "    class_labels = label_encoder.classes_\n",
    "    \n",
    "    for num, imp in enumerate(importances):\n",
    "        emotion = class_labels[num]\n",
    "        topn = sorted(zip(imp,names), reverse=True)[:n]\n",
    "        \n",
    "        print(\"Important words in {} utterances\".format(emotion))\n",
    "        for coef, feat in topn:\n",
    "            print(emotion, coef, feat)\n",
    "        print(\"-----------------------------------------\")\n",
    "\n",
    "print('Most important features per emotion: 3A')\n",
    "feature_names = utterance_vec_3A.get_feature_names()\n",
    "importances = average_importances(svm_linear_clf_3A)\n",
    "f_importances(importances, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f8e622-4e4d-4f61-83eb-82c121f871dd",
   "metadata": {},
   "source": [
    "### Filter B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c676bfc-cd46-453c-a707-68a503f8ad53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determiner and pronouns {'@sarahb45', 'no', 'i', \"\\\\n\\\\n'you\", '@capitalone', 'blm', \"naya'\\\\n\\\\n'i\", \"i'm\", '😿', '#behaviour', 'tbh', 'em', '@interception225', 'himself', 'ios10', 'every', '@aefadul22', 'this', 'myself', 'it.\\\\n#funny', '@barackobama', 'ours', 'your', '@the', 'yourself', '@ritujai18874', '@messyourself', '✨', 'that,\\\\ngives', '#', 'itself', '@bbnicole', 'theirs', '@barbour', 'you', '@digger_forum', 'ourselves', \"'s\", 'its', '@rosie', '»', '@johnjharwood', '@jankhambrams', 'an', \"you're\", 'lv', '’s', 'any', 'one', '@eliroth', '\\\\nso', 'those', 'each', 'd', '@realdonaldtrump', '@your', 'themselves', 'his', '😑', '🍂', '@space_gayz', 'lt', '😄', 'my', 'they', 'ya', '\\\\nmatt', 'yours', '@jdegrom19', '@jbanks88', 'another', 'yhat', 'nj@latimes', 'tho', \"y'\", 'it', 'her', '@talktalkcare', 'tvgirl', 'the', 'y', 'boys', '@ryuredwings2', '\\\\nindia', '@xmaseveevil1', 'their', '@adele', 'she', '_', 'either', 'stupid?that', '\\\\nwhat', \"they're\", 'we', 'some', 'these', \"i'i\", 'all', 'a', 'he', 'isthereahelplineforthis', 'hers', 'u', '@colinoccupantz', 'happy\\\\nshe', '😊', 'half', 'thee', \"'em\", 'said!!!!\\\\nthey', '💦', 'our', \"my'this\", 'that', 'thy', 'both', 'mine', '@kristasaidthis', 'neither'}\n",
      "Min_df 2\n"
     ]
    }
   ],
   "source": [
    "low_df_test_3B, DTandPRP_test_3B, clean_test_3B = \\\n",
    "remove_DT_PRP(2, test_data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31d05227-29b4-4f34-898a-6a01385559c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_count_3B = utterance_vec_3B.transform(clean_test_3B)\n",
    "test_tfidf_3B = tfidf_transformer.fit_transform(test_count_3B)\n",
    "\n",
    "y_pred_svm_3B = svm_linear_clf_3B.predict(test_tfidf_3B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fce4c065-36c1-47b2-87ce-3602e10dab31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'disgust' 'fear' 'joy' 'sadness' 'surprise']\n",
      "BoW TFIDF SVM LINEAR: MELD+Tweets, Filter B\n",
      "Word mininum document frequency 2 ; DT PRP removed\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.705584  0.628959  0.665072      1105\n",
      "           1   0.444444  0.058824  0.103896        68\n",
      "           2   0.809101  0.697608  0.749229      1045\n",
      "           3   0.626834  0.803763  0.704358      1116\n",
      "           4   0.701887  0.633371  0.665871       881\n",
      "           5   0.477333  0.637011  0.545732       281\n",
      "\n",
      "    accuracy                       0.681050      4496\n",
      "   macro avg   0.627531  0.576589  0.572360      4496\n",
      "weighted avg   0.691157  0.681050  0.678594      4496\n",
      "\n",
      "Confusion matrix SVM, BoW MELD+Tweets, Filter B\n",
      "['anger' 'disgust' 'fear' 'joy' 'sadness' 'surprise']\n",
      "[[695   0  61 207  74  68]\n",
      " [ 19   4   3  23   7  12]\n",
      " [ 76   3 729 111  93  33]\n",
      " [ 65   1  49 897  56  48]\n",
      " [103   1  54 130 558  35]\n",
      " [ 27   0   5  63   7 179]]\n"
     ]
    }
   ],
   "source": [
    "report3B = classification_report(test_classes,y_pred_svm_3B,digits = 6)\n",
    "print(label_encoder.classes_)\n",
    "print('BoW TFIDF SVM LINEAR: MELD+Tweets, Filter B')\n",
    "print('Word mininum document frequency', min_df, \"; DT PRP removed\")\n",
    "print(report3B)\n",
    "\n",
    "print('Confusion matrix SVM, BoW MELD+Tweets, Filter B')\n",
    "print(label_encoder.classes_)\n",
    "print(sklearn.metrics.confusion_matrix(test_classes,y_pred_svm_3B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4813af15-5dfb-4fc4-901a-e8227a49a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probabilities_3B = svm_linear_clf_3B.predict_proba(test_tfidf_3B)\n",
    "\n",
    "pred_labels_3B = []\n",
    "for predicted_label in y_pred_svm_3B:\n",
    "    pred_labels_3B.append(label_encoder.classes_[predicted_label])\n",
    "\n",
    "gold_labels_3B = []\n",
    "for gold_label in test_classes:\n",
    "    gold_labels_3B.append(label_encoder.classes_[gold_label])\n",
    "\n",
    "result_frame3B = pd.DataFrame(pred_probabilities_3B*100, columns=label_encoder.classes_)\n",
    "\n",
    "result_frame3B['Chat']= list(combined_dftest['Sent'])\n",
    "result_frame3B['Prediction']=pred_labels_3B\n",
    "result_frame3B['Gold']=gold_labels_3B\n",
    "\n",
    "result_frame3B.to_csv(\"result_frame3B.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "63f6364d-ae9c-4357-b210-1ab06ba85cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>Chat</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.635362</td>\n",
       "      <td>5.189763</td>\n",
       "      <td>16.871482</td>\n",
       "      <td>17.626829</td>\n",
       "      <td>22.579746</td>\n",
       "      <td>30.096819</td>\n",
       "      <td>Why do all you're coffee mugs have numbers on ...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.809647</td>\n",
       "      <td>3.599743</td>\n",
       "      <td>4.471020</td>\n",
       "      <td>54.886823</td>\n",
       "      <td>21.225968</td>\n",
       "      <td>2.006798</td>\n",
       "      <td>Oh. That's so Monica can keep track. That way ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.387124</td>\n",
       "      <td>4.072070</td>\n",
       "      <td>4.512778</td>\n",
       "      <td>15.452332</td>\n",
       "      <td>31.103080</td>\n",
       "      <td>17.472617</td>\n",
       "      <td>Push!</td>\n",
       "      <td>sadness</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.596840</td>\n",
       "      <td>4.697395</td>\n",
       "      <td>4.286271</td>\n",
       "      <td>6.929665</td>\n",
       "      <td>65.700451</td>\n",
       "      <td>2.789377</td>\n",
       "      <td>Push 'em out, push 'em out, harder, harder.</td>\n",
       "      <td>sadness</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.886224</td>\n",
       "      <td>4.271482</td>\n",
       "      <td>6.069298</td>\n",
       "      <td>14.626383</td>\n",
       "      <td>28.512423</td>\n",
       "      <td>15.634190</td>\n",
       "      <td>Push 'em out, push 'em out, way out!</td>\n",
       "      <td>anger</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       anger   disgust       fear        joy    sadness   surprise  \\\n",
       "0   7.635362  5.189763  16.871482  17.626829  22.579746  30.096819   \n",
       "1  13.809647  3.599743   4.471020  54.886823  21.225968   2.006798   \n",
       "2  27.387124  4.072070   4.512778  15.452332  31.103080  17.472617   \n",
       "3  15.596840  4.697395   4.286271   6.929665  65.700451   2.789377   \n",
       "4  30.886224  4.271482   6.069298  14.626383  28.512423  15.634190   \n",
       "\n",
       "                                                Chat Prediction      Gold  \n",
       "0  Why do all you're coffee mugs have numbers on ...   surprise  surprise  \n",
       "1  Oh. That's so Monica can keep track. That way ...        joy     anger  \n",
       "2                                              Push!    sadness       joy  \n",
       "3        Push 'em out, push 'em out, harder, harder.    sadness       joy  \n",
       "4               Push 'em out, push 'em out, way out!      anger       joy  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame3B.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6073a634-b02d-4327-87b7-9b1bd5583208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important features per emotion for the SVM classifier\n",
      "Important words in anger utterances\n",
      "anger 3.9517599889013715 rage\n",
      "anger 3.922396823933238 anger\n",
      "anger 3.517524094713816 offend\n",
      "anger 3.493768271415148 angry\n",
      "anger 3.332648121069419 bitter\n",
      "anger 2.98024029625986 fury\n",
      "anger 2.963529688697942 revenge\n",
      "anger 2.9311406328470833 offense\n",
      "anger 2.877865890601306 burst\n",
      "anger 2.831146054666674 fume\n",
      "anger 2.703502622967309 furious\n",
      "anger 2.606341356066631 wrath\n",
      "anger 2.5946693596563235 madden\n",
      "anger 2.5847650912785753 rabid\n",
      "anger 2.578290625839091 snap\n",
      "anger 2.5721717238101998 relentless\n",
      "anger 2.5538142586967756 resent\n",
      "anger 2.5461598529838287 outrage\n",
      "anger 2.4712136549583734 insult\n",
      "anger 2.4512561381079156 irritate\n",
      "-----------------------------------------\n",
      "Important words in disgust utterances\n",
      "disgust 1.7942395097464097 disgusting\n",
      "disgust 1.6954919980888725 eww\n",
      "disgust 1.672789381620575 violate\n",
      "disgust 1.665964701307622 ew\n",
      "disgust 1.557465856724705 behave\n",
      "disgust 1.5512814425383408 clinic\n",
      "disgust 1.5344949752277919 boat\n",
      "disgust 1.4255283559377914 drug\n",
      "disgust 1.361386124617883 ugh\n",
      "disgust 1.345187198717045 pig\n",
      "disgust 1.3064407777030562 shame\n",
      "disgust 1.257684589891216 mindy\n",
      "disgust 1.1930584074492951 officially\n",
      "disgust 1.1506726608839368 o\n",
      "disgust 1.145869089604206 toilet\n",
      "disgust 1.1444144113633017 smell\n",
      "disgust 1.137007017536828 hairy\n",
      "disgust 1.124603583672616 buck\n",
      "disgust 1.1118735987336081 hate\n",
      "disgust 1.102243857682243 heel\n",
      "-----------------------------------------\n",
      "Important words in fear utterances\n",
      "fear 3.578879754359074 terrorism\n",
      "fear 3.4072292678722915 horror\n",
      "fear 3.2451125074601337 shake\n",
      "fear 3.1548796063492484 bully\n",
      "fear 3.148959919003589 awe\n",
      "fear 3.129137266596186 fear\n",
      "fear 3.0791349093341416 nightmare\n",
      "fear 2.9391236522997284 shy\n",
      "fear 2.937734959156752 terror\n",
      "fear 2.6806357812286286 panic\n",
      "fear 2.5492983019218594 horrific\n",
      "fear 2.4370270847451825 nervous\n",
      "fear 2.415010226456292 shocking\n",
      "fear 2.3876759263210543 dread\n",
      "fear 2.3765335876887526 concern\n",
      "fear 2.333959447705253 afraid\n",
      "fear 2.3295892190013303 awful\n",
      "fear 2.324513637858637 horrible\n",
      "fear 2.262067438823017 hesitate\n",
      "fear 2.2030110142213166 intimidate\n",
      "-----------------------------------------\n",
      "Important words in joy utterances\n",
      "joy 3.3461268041661514 glee\n",
      "joy 3.2009607564566203 cheer\n",
      "joy 3.170869388567972 hilarious\n",
      "joy 3.159252367133751 elated\n",
      "joy 3.056860210784053 playful\n",
      "joy 3.0375988005553207 rejoice\n",
      "joy 2.907611088480338 optimism\n",
      "joy 2.834504970010586 joyous\n",
      "joy 2.616668239160907 smile\n",
      "joy 2.5992509016588494 exhilarate\n",
      "joy 2.5940934219596556 laughter\n",
      "joy 2.5759037534602696 lively\n",
      "joy 2.569568762946663 cheerfully\n",
      "joy 2.5382822562791025 animate\n",
      "joy 2.4673466594623474 joyful\n",
      "joy 2.438040947529357 cheerful\n",
      "joy 2.43451770745762 hearty\n",
      "joy 2.4105662572344597 heyday\n",
      "joy 2.3859237068894306 delight\n",
      "joy 2.3026113563035944 breezy\n",
      "-----------------------------------------\n",
      "Important words in sadness utterances\n",
      "sadness 3.554782057367035 unhappy\n",
      "sadness 3.4769477266930116 depressing\n",
      "sadness 3.3183205593712892 grim\n",
      "sadness 3.2823939139484977 sober\n",
      "sadness 3.1795657779310105 dark\n",
      "sadness 3.174246649645844 pine\n",
      "sadness 3.1469506782398833 blue\n",
      "sadness 3.0459546485736375 depress\n",
      "sadness 3.022808492418785 depression\n",
      "sadness 2.7813127925105205 pessimist\n",
      "sadness 2.7796676889342953 sink\n",
      "sadness 2.772341481656287 dull\n",
      "sadness 2.7694132898147226 discourage\n",
      "sadness 2.7359949652648425 sad\n",
      "sadness 2.654181873278266 weary\n",
      "sadness 2.650405180082396 gloomy\n",
      "sadness 2.6338192931569218 sadly\n",
      "sadness 2.571632093880323 gloom\n",
      "sadness 2.4963568137700234 mourn\n",
      "sadness 2.4830217511643466 sadness\n",
      "-----------------------------------------\n",
      "Important words in surprise utterances\n",
      "surprise 2.282508064559522 ?\n",
      "surprise 2.0374444079249066 wow\n",
      "surprise 1.7391393439955418 whoa\n",
      "surprise 1.697889202837199 julio\n",
      "surprise 1.6276981777644433 believe\n",
      "surprise 1.6206883779390917 oww\n",
      "surprise 1.532487739934826 dancer\n",
      "surprise 1.5132452563666228 dress\n",
      "surprise 1.4712794454084182 my\n",
      "surprise 1.4514275445182336 contraction\n",
      "surprise 1.4434740024612105 fool\n",
      "surprise 1.4295804938146603 size\n",
      "surprise 1.3663623450851423 40\n",
      "surprise 1.33508988298193 wha\n",
      "surprise 1.2983100138151678 yike\n",
      "surprise 1.2826068093861143 snuggle\n",
      "surprise 1.256300438060392 goggle\n",
      "surprise 1.2531506146230686 device\n",
      "surprise 1.235252751030011 mark\n",
      "surprise 1.2337634363050205 word\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Most important features per emotion for the SVM classifier')\n",
    "feature_names = utterance_vec_3B.get_feature_names()\n",
    "importances = average_importances(svm_linear_clf_3B)\n",
    "f_importances(importances, feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
