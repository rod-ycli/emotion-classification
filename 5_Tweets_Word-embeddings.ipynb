{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c09547e-9a7d-4fb5-94ca-1e87df66694b",
   "metadata": {},
   "source": [
    "# 5. Tweets, Word-embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edd1c61-f66c-460b-931d-6e807aa337bc",
   "metadata": {},
   "source": [
    "## 5.1 Data preparation and filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa8ab59-711a-4164-80aa-dfee54270eb9",
   "metadata": {},
   "source": [
    "(a) Loading the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab521505-7767-4fd4-a82f-dcc0e66ae8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "filepath = 'data/wassa/training/all.train.tsv'\n",
    "tweets_dftrain = pd.read_csv(filepath, sep='\\t')\n",
    "\n",
    "filepath = 'data/wassa/testing/all.test.tsv'\n",
    "tweets_dftest = pd.read_csv(filepath, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bd1da9-95b2-4009-9ebd-6df497e193c3",
   "metadata": {},
   "source": [
    "(b) Tokenizing and filtering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdb222ae-9266-485d-8e29-b03391400cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using spaCy to tokenize the sentences\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "                 \n",
    "training_data_5 = [nlp(sent) for sent in list(tweets_dftrain['Tweet'])]\n",
    "training_labels_5 = list(tweets_dftrain['Label'])\n",
    "\n",
    "test_data_5 = [nlp(sent) for sent in list(tweets_dftest['Tweet'])]\n",
    "test_labels_5 = list(tweets_dftest['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a29853-de60-4110-99d9-4b5745389cb4",
   "metadata": {},
   "source": [
    "### Filter A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4686137-7d97-4622-b1ba-047b6b0c9d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_df 2\n",
      "Max_df 361\n",
      "Rare words with low df =  5295 words. Examples:  ['@rbrutti', '@kevinrouth', 'afaik', 'ollaf', 'making', '@moamali', 'attendance', 'stfuuu', 'me?\\\\n', 'dnt', 'Ô∏è&amp', 'blessings', 'cn', 'ku', '@blvdcenter', '@jackie_mansky', '@courtneymee', 'lesson', 'grapefruit', 'division']\n",
      "Stop words with high df: {'do', 'in', 'to', '#', 'that', 'have', 'my', 'a', 'of', '!', 'i', 'the', \"n't\", 'and', 'on', '.', 'it', 'for', ' ', 'be', 'you', ','}\n",
      "Size of the rest vocab: 4190\n",
      "Samples: [['m', 'so', 'mad', 'about', 'power', 'ranger', 'm', 'incense', 'm', 'furious'], ['wo', 'nt', 'use', 'use', '@mothercareuk', '@mothercarehelp', 'again', 'these', 'guy', 'ca', 'nt', 'get', 'nothing', 'right', 'fume'], ['bitch', 'aggravate', 'like', 'what', 'inspire', 'big', 'cunt', 'know', 'man', 'kind', '?'], ['why', '@dapperlaugh', 'come', 'glasgow', 'night', 'work', 'fucking', 'gutte', 'wait', 'an', 'appearance', 'age', 'rage'], ['fume', 'üò§'], ['zero', 'help', 'from', '@up', 'customer', 'service', 'just', 'push', 'buck', 'back', 'forth', 'promise', 'callback', 'n‚Äôt', 'happen', 'anger'], ['not', 'mention', 'guy', 'stop', 'but', 'let', \"'s\", '2', 'ppl', 'front', 'go', 'wtf', 'blood', 'boil'], ['hate', 'if', 'soul', \"'d\", 'fiery', 'hell'], ['why', 'people', 'so', 'offend', 'by', 'kendall', 'he', 'end', 'photo', 'shoot', 'like', 'seriously', 'shut', 'fuck', 'up'], ['about', 'block', 'everyone', 'everywhere', 'post', 'about', 'storm', 'think', 'everyone', 'aware', 'damn', 'rain', 'what', 'not', 'so', 'quit', 'damn']]\n"
     ]
    }
   ],
   "source": [
    "from utils import low_high_mid_df\n",
    "min_df = 2\n",
    "max_df = len(training_data_5)//10\n",
    "\n",
    "low_df, high_df, clean5A = low_high_mid_df(min_df, max_df, training_data_5)\n",
    "\n",
    "print(\"Rare words with low df = \", len(low_df), \"words. Examples: \", list(low_df)[:20])\n",
    "print(\"Stop words with high df:\", high_df)\n",
    "vocab_5A = set()\n",
    "for sent in clean5A:\n",
    "    for t in sent:\n",
    "        vocab_5A.add(t)\n",
    "print(\"Size of the rest vocab:\", len(vocab_5A))\n",
    "print(\"Samples:\", clean5A[10:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb8dec7-a76b-4310-b988-473c38505150",
   "metadata": {},
   "source": [
    "### Filter B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e446e76-b2bc-462f-9436-33c93becb0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determiner and pronouns {'@neyaphemmaster', 'no', 'tbh', 'üòä', 'ty', '‚Äôs', 'tho', 'üçÅ', 'himself', 'the', '@melissajoyrd', '@m_t_f_72', '\\\\nit', 'oldham\\\\nnext', 'they', 'em', 'either', 'scarred,\\\\nthis', 'itself', 'we', 'it', 'its', ':)', 'an', 'don‚Äôt', 'our', 'n', 'these', '@smshow', '@rowillfindyou', '‚ù§', 'each', 'u', 'isthereahelplineforthis', '\\\\nimagine', 'some', '@british_airways', 'i', 'those', 'bridgetjonesbaby', 'ourselves', '@sargon_of_akkad', '@weebtard', 'their', 'hers', 'themselves', 'herself', 'he', 'this', 'üêÆ', 'also-', 'yours', 'myself', 'hbu', 'her', '@its.finfin', 'every', 'yourself', '@missmeliss465', '@reyesaverie', '#', 'that', \"'s\", '@adsbyflaherty', 'a', 'y', 'another', \"y'\", 'one', 'both', '@kevincanwaitcbs', 'she', 'your', 'strength.\\\\nthey', '\\\\n\\\\nother', 'üêà', '@mhchat', '‚ú®', '@blackeyed_susie', \"you're\", '_', '\\uf62b', '@themathofyou', 'near,\\\\nthe', 'üòß', 'all', '@ntfc', '@fra93_bruno', 'üò°', 'my', 'his', 'memphis', 'any', 'xx', '@relaqss', '@ryyyshh', 'ya', '@snub23', 'üëÖ', 'eagles.\\\\nthey', 'jut', 'd', '\\\\n\\\\nsam', 'you', '\\\\n#you', 'thy', 'ek', 'mine'}\n",
      "Min_df 2\n",
      "Rare words with low df =  5272 words. Examples: ['@rbrutti', '@kevinrouth', 'afaik', 'ollaf', 'making', '@moamali', 'attendance', 'stfuuu', 'me?\\\\n', 'dnt', 'Ô∏è&amp', 'blessings', 'cn', 'ku', '@blvdcenter', '@jackie_mansky', '@courtneymee', 'lesson', 'grapefruit', 'division']\n",
      "Size of the rest vocab: 4167\n",
      "Samples: [['m', 'so', 'mad', 'about', 'power', 'ranger', '.', 'm', 'incense', '.', 'm', 'furious', '.'], ['wo', 'nt', 'use', 'use', '@mothercareuk', '@mothercarehelp', 'again', '!', '!', 'guy', 'ca', 'nt', 'get', 'nothing', 'right', '!', '!', '#', 'fume'], ['bitch', 'aggravate', 'like', 'what', 'inspire', 'to', 'be', 'big', 'cunt', 'know', 'to', 'man', 'kind', '?'], ['why', 'do', '@dapperlaugh', 'have', 'to', 'come', 'to', 'glasgow', 'on', 'night', 'be', 'work', '.', 'be', 'fucking', 'gutte', ',', 'be', 'wait', 'for', 'appearance', 'for', 'age', '#', 'rage'], ['fume', 'üò§'], ['zero', 'help', 'from', '@up', 'customer', 'service', '.', 'just', 'push', 'buck', 'back', 'and', 'forth', 'and', 'promise', 'callback', 'that', 'do', 'n‚Äôt', 'happen', '.', '#', 'anger', '#'], ['not', 'to', 'mention', 'guy', 'stop', 'but', 'let', '2', 'ppl', 'in', 'front', 'of', 'go', '.', 'wtf', '.', 'blood', 'be', 'boil', '.'], ['hate', '.', 'if', 'have', 'soul', ',', \"'d\", 'to', 'fiery', 'of', 'hell', '.'], ['why', 'be', 'people', 'so', 'offend', 'by', 'kendall', 'end', 'photo', 'shoot', 'like', 'seriously', 'shut', 'fuck', 'up'], ['be', 'about', 'to', 'block', 'everyone', 'everywhere', 'post', 'about', 'storm', '.', 'think', 'everyone', 'be', 'aware', 'of', 'damn', 'rain', 'and', 'what', 'not', 'so', 'quit', '.', '#', 'damn']]\n"
     ]
    }
   ],
   "source": [
    "from utils import remove_DT_PRP\n",
    "\n",
    "min_df = 2\n",
    "\n",
    "low_df, DTandPRP_tok, clean5B = remove_DT_PRP(min_df, training_data_5)\n",
    "\n",
    "print(\"Rare words with low df = \", len(low_df), \"words. Examples:\", list(low_df)[:20])\n",
    "vocab_5B = set()\n",
    "for sent in clean5B:\n",
    "    for t in sent:\n",
    "        vocab_5B.add(t)\n",
    "print(\"Size of the rest vocab:\", len(vocab_5B))\n",
    "print(\"Samples:\", clean5B[10:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8e959f-6578-46b0-8ea4-6535ef86951d",
   "metadata": {},
   "source": [
    "## 5.2 Word-embedding model and training the classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbddd28b-c267-4d97-87e3-4730986673e4",
   "metadata": {},
   "source": [
    "(a) Encoding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a10698ca-a48c-4fa3-92e2-011c201be758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'fear', 'joy', 'sadness']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(training_labels_5+test_labels_5)\n",
    "print(list(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "888754b2-aabd-4efc-ad33-3eb27af00ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n",
      "['anger', 'anger', 'anger', 'anger', 'anger']\n",
      "['How the fu*k! Who the heck! moved my fridge!... should I knock the landlord door. #angry #mad ##', \"So my Indian Uber driver just called someone the N word. If I wasn't in a moving vehicle I'd have jumped out #disgusted \", '@DPD_UK I asked for my parcel to be delivered to a pick up store not my address #fuming #poorcustomerservice', 'so ef whichever butt wipe pulled the fire alarm in davis bc I was sound asleep #pissed #angry #upset #tired #sad #tired #hangry ######', \"Don't join @BTCare they put the phone down on you, talk over you and are rude. Taking money out of my acc willynilly! #fuming\"]\n"
     ]
    }
   ],
   "source": [
    "training_classes = label_encoder.transform(training_labels_5)\n",
    "print(training_classes[:5])\n",
    "print(list(tweets_dftrain['Label'])[:5])\n",
    "print(list(tweets_dftrain['Tweet'])[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b930556e-7f9b-4083-9d64-7b401f123c8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "(b) Loading the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0161bbeb-21a3-4241-8805-e66d104dc0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-dc66f279bafc>:12: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  _ = glove2word2vec(glove_file, tmp_file)\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "from os import path\n",
    "\n",
    "wordembeddings=\"glove.twitter.27B.200d.txt\"\n",
    "glove_file = datapath(path.abspath('../glove/glove.twitter.27B.200d.txt'))\n",
    "\n",
    "# Create a word2vec model from the Glove text data\n",
    "tmp_file = get_tmpfile(\"test_word2vec.txt\")\n",
    "_ = glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "word_embedding_model = KeyedVectors.load_word2vec_format(tmp_file)\n",
    "\n",
    "# Dimensions set to 200.\n",
    "num_features = 200\n",
    "\n",
    "# Converting Index2Word\n",
    "index2word_set = set(word_embedding_model.index_to_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda92b8e-35dd-457f-a1be-71f72efb7895",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Filter A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "892d7d42-bd1b-4287-aaae-0c76ef32848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of our matrix is: (3613, 200)\n",
      "Review 0 of 3613\n",
      "Review 1000 of 3613\n",
      "Review 2000 of 3613\n",
      "Review 3000 of 3613\n"
     ]
    }
   ],
   "source": [
    "from utils import featureVecMethod, getAvgFeatureVecs\n",
    "\n",
    "trainFeatureVecs_5A, embedding_words_5A, no_embedding_words_5A = \\\n",
    "getAvgFeatureVecs(clean5A,\n",
    "                  word_embedding_model, \n",
    "                  index2word_set, \n",
    "                  num_features\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "649db7f7-65f6-4c0b-9b2d-95915ec15820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how', 'who', 'heck', 'move', 'fridge', 'should', 'knock', 'landlord', 'door', 'angry', 'mad', 'so', 'indian', 'uber', 'driver', 'just', 'call', 'someone', 'n', 'word', 'if', 'move', 'vehicle', \"'d\", 'jump', 'out', 'disgusted', 'ask', 'parcel', 'deliver', 'pick', 'up', 'store', 'not', 'address', 'fume', 'so', 'ef', 'whichever', 'butt', 'wipe', 'pull', 'fire', 'alarm', 'davis', 'bc', 'sound', 'asleep', 'piss', 'angry']\n",
      "\n",
      "['fu*k', '...', '@dpd_uk', 'poorcustomerservice', '@btcare', 'willynilly', 'üò≠', 'üò≠', '@__kirstyga', 'oldcunt', '@bt_uk', '3', '@mothercareuk', '@mothercarehelp', '@dapperlaugh', 'üò§', '@up', '2', 'ü§ó', 'üëå', 'üèª', 'hoopjunkie', 'f*c@n', 'üòû', 'üòû', '\\\\nwhy', '..', 'immobilize', '.@divamagazine', 'üòí', 'üí∏', 'üòí', '@vodafoneukhelp', '@vodafoneuk', '44.77', '148', '@iphone', '40', '10', '@barclaysuk', 'treatcustomersfairly', '@ggreenwald', '5', '6', '@thomsoncare', 'sam-', '@ya_boi_huck', 'huckfp2', '@dapperlaugh', 'üòÇ']\n"
     ]
    }
   ],
   "source": [
    "print(embedding_words_5A[:50])\n",
    "print()\n",
    "print(no_embedding_words_5A[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5c43afe-d127-4623-81f9-16b298bd1569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=LinearSVC(max_iter=2000), cv=10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "linear_model = svm.LinearSVC(max_iter=2000)\n",
    "svm_linear_clf_5A = CalibratedClassifierCV(linear_model , method='sigmoid', cv=10)\n",
    "\n",
    "svm_linear_clf_5A.fit(trainFeatureVecs_5A, training_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87cd4e8-f0b2-478e-9c86-9f3970061820",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Filter B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a32f6be2-c67f-4071-ad1d-88263065a6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of our matrix is: (3613, 200)\n",
      "Review 0 of 3613\n",
      "Review 1000 of 3613\n",
      "Review 2000 of 3613\n",
      "Review 3000 of 3613\n"
     ]
    }
   ],
   "source": [
    "trainFeatureVecs_5B, embedding_words_5B, no_embedding_words_5B = \\\n",
    "getAvgFeatureVecs(clean5B,\n",
    "                  word_embedding_model, \n",
    "                  index2word_set, \n",
    "                  num_features\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "003e7956-8227-4186-a875-aa87a4e235ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how', '!', 'who', 'heck', '!', 'move', 'fridge', '!', 'should', 'knock', 'landlord', 'door', '.', '#', 'angry', '#', 'mad', '#', '#', 'so', 'indian', 'uber', 'driver', 'just', 'call', 'someone', 'n', 'word', '.', 'if', 'be', \"n't\", 'in', 'move', 'vehicle', \"'d\", 'have', 'jump', 'out', '#', 'disgusted', 'ask', 'for', 'parcel', 'to', 'be', 'deliver', 'to', 'pick', 'up']\n",
      "\n",
      "['fu*k', '...', '@dpd_uk', 'poorcustomerservice', '@btcare', 'willynilly', 'üò≠', 'üò≠', '@__kirstyga', 'oldcunt', '@bt_uk', '3', '@mothercareuk', '@mothercarehelp', '@dapperlaugh', 'üò§', '@up', '2', 'ü§ó', 'üëå', 'üèª', 'hoopjunkie', 'f*c@n', 'üòû', 'üòû', '\\\\nwhy', '..', 'immobilize', ' ', '.@divamagazine', 'üòí', 'üí∏', 'üòí', '@vodafoneukhelp', '@vodafoneuk', '44.77', '148', '@iphone', '40', ' ', '10', '@barclaysuk', 'treatcustomersfairly', '@ggreenwald', '5', '6', '@thomsoncare', 'sam-', '@ya_boi_huck', 'huckfp2']\n"
     ]
    }
   ],
   "source": [
    "print(embedding_words_5B[:50])\n",
    "print()\n",
    "print(no_embedding_words_5B[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c27c8747-5598-4bc9-9470-144e34d5b74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=LinearSVC(max_iter=2000), cv=10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = svm.LinearSVC(max_iter=2000)\n",
    "svm_linear_clf_5B = CalibratedClassifierCV(linear_model , method='sigmoid', cv=10)\n",
    "\n",
    "svm_linear_clf_5B.fit(trainFeatureVecs_5B, training_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4354c311-73ef-4a7b-847a-8fa19006dd7e",
   "metadata": {},
   "source": [
    "## 5.3 Predicting the test data and results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2683e951-d74f-4a02-b512-ce94c47c224e",
   "metadata": {},
   "source": [
    "Encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f469c20b-ecf6-4644-9644-e4e2d84b64c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n",
      "['anger', 'anger', 'anger', 'anger', 'anger']\n",
      "['At the point today where if someone says something remotely kind to me, a waterfall will burst out of my eyes', \"@CorningFootball  IT'S GAME DAY!!!!      T MINUS 14:30  #relentless\", 'This game has pissed me off more than any other game this year. My blood is boiling! Time to turn it off! #STLCards', \"@spamvicious I've just found out it's Candice and not Candace. She can pout all she likes for me üòç\", \"@moocowward @mrsajhargreaves @Melly77 @GaryBarlow if he can't come to my Mum'a 60th after 25k tweets then why should I üôà  #soreloser\"]\n"
     ]
    }
   ],
   "source": [
    "test_classes_5 = label_encoder.transform(test_labels_5)\n",
    "print(test_classes_5[:5])\n",
    "print(list(tweets_dftest['Label'])[:5])\n",
    "print(list(tweets_dftest['Tweet'])[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da5d2da-cc44-45de-abbe-83f209103b18",
   "metadata": {},
   "source": [
    "### Filter A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc67d7-ddd5-4aa0-8cab-c7fa7b4c62a8",
   "metadata": {},
   "source": [
    "(a) Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a51ca46-cf3a-40d7-85e8-976f5ff67951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_df 2\n",
      "Max_df 314\n"
     ]
    }
   ],
   "source": [
    "max_df_test = len(test_data_5)//10\n",
    "\n",
    "low_df_test_5A, high_df_test_5A, test_mid_df_5A = \\\n",
    "low_high_mid_df(2, max_df_test, test_data_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12a25db9-a8de-44cf-bb1e-ea524227626e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'do', 'in', 'to', '#', 'that', 'have', 'my', 'a', 'of', '!', 'i', 'the', \"n't\", 'and', 'on', '.', 'it', 'for', ' ', 'be', 'you', ','}\n"
     ]
    }
   ],
   "source": [
    "print(high_df_test_5A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e92cd7c-bcb4-436c-be20-a8f24fb8a4cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of our matrix is: (3142, 200)\n",
      "Review 0 of 3142\n",
      "Review 1000 of 3142\n",
      "Review 2000 of 3142\n",
      "Review 3000 of 3142\n"
     ]
    }
   ],
   "source": [
    "testDataVecs_5A, test_5A_known_words, test_5A_unknown_words =\\\n",
    "getAvgFeatureVecs(test_mid_df_5A,\n",
    "                  word_embedding_model, \n",
    "                  index2word_set, \n",
    "                  num_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6522eaf-1a74-4ac2-82d2-629f328b280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_5A = svm_linear_clf_5A.predict(testDataVecs_5A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fec3ee5-28e9-4410-92d0-7b2c9e76a16a",
   "metadata": {},
   "source": [
    "(b) Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f990db4-ea96-4aad-83ff-08c120bf626f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'fear' 'joy' 'sadness']\n",
      "Embeddings SVM LINEAR: Tweets, Filter A\n",
      "Word embedding model used glove.twitter.27B.200d.txt\n",
      "Word mininum document frequency 2 : max: 314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.691761  0.640789  0.665301       760\n",
      "           1   0.683744  0.697487  0.690547       995\n",
      "           2   0.682219  0.757703  0.717983       714\n",
      "           3   0.636508  0.595840  0.615503       673\n",
      "\n",
      "    accuracy                       0.675684      3142\n",
      "   macro avg   0.673558  0.672955  0.672333      3142\n",
      "weighted avg   0.675219  0.675684  0.674601      3142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Evaluating and analyzing the result\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report_5A = classification_report(test_classes_5,y_pred_svm_5A,digits = 6)\n",
    "print(label_encoder.classes_)\n",
    "print('Embeddings SVM LINEAR: Tweets, Filter A')\n",
    "print('Word embedding model used', wordembeddings)\n",
    "print('Word mininum document frequency', min_df, \": max:\", max_df_test)\n",
    "print(report_5A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0c5fc9a-8dcb-40ee-9f09-c750642d13c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix SVM, embeddings, Tweets, Filter A\n",
      "['anger' 'fear' 'joy' 'sadness']\n",
      "[[487 124  79  70]\n",
      " [104 694  92 105]\n",
      " [ 38  81 541  54]\n",
      " [ 75 116  81 401]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print('Confusion matrix SVM, embeddings, Tweets, Filter A')\n",
    "print(label_encoder.classes_)\n",
    "print(sklearn.metrics.confusion_matrix(test_classes_5,y_pred_svm_5A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a3e2224-9ead-4af4-91a7-3df7c797cdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>Chat</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.646578</td>\n",
       "      <td>22.134382</td>\n",
       "      <td>16.334299</td>\n",
       "      <td>23.884741</td>\n",
       "      <td>At the point today where if someone says somet...</td>\n",
       "      <td>anger</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.890805</td>\n",
       "      <td>15.365714</td>\n",
       "      <td>18.820500</td>\n",
       "      <td>4.922980</td>\n",
       "      <td>@CorningFootball  IT'S GAME DAY!!!!      T MIN...</td>\n",
       "      <td>anger</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.422019</td>\n",
       "      <td>5.877677</td>\n",
       "      <td>7.032385</td>\n",
       "      <td>14.667920</td>\n",
       "      <td>This game has pissed me off more than any othe...</td>\n",
       "      <td>anger</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.053478</td>\n",
       "      <td>15.828589</td>\n",
       "      <td>55.478675</td>\n",
       "      <td>10.639258</td>\n",
       "      <td>@spamvicious I've just found out it's Candice ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.196309</td>\n",
       "      <td>29.817172</td>\n",
       "      <td>11.337498</td>\n",
       "      <td>20.649020</td>\n",
       "      <td>@moocowward @mrsajhargreaves @Melly77 @GaryBar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       anger       fear        joy    sadness  \\\n",
       "0  37.646578  22.134382  16.334299  23.884741   \n",
       "1  60.890805  15.365714  18.820500   4.922980   \n",
       "2  72.422019   5.877677   7.032385  14.667920   \n",
       "3  18.053478  15.828589  55.478675  10.639258   \n",
       "4  38.196309  29.817172  11.337498  20.649020   \n",
       "\n",
       "                                                Chat Prediction   Gold  \n",
       "0  At the point today where if someone says somet...      anger  anger  \n",
       "1  @CorningFootball  IT'S GAME DAY!!!!      T MIN...      anger  anger  \n",
       "2  This game has pissed me off more than any othe...      anger  anger  \n",
       "3  @spamvicious I've just found out it's Candice ...        joy  anger  \n",
       "4  @moocowward @mrsajhargreaves @Melly77 @GaryBar...      anger  anger  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probabilities_5A = svm_linear_clf_5A.predict_proba(testDataVecs_5A)\n",
    "\n",
    "pred_labels_5A = []\n",
    "for predicted_label in y_pred_svm_5A:\n",
    "    pred_labels_5A.append(label_encoder.classes_[predicted_label])\n",
    "\n",
    "gold_labels_5A = []\n",
    "for gold_label in test_classes_5:\n",
    "    gold_labels_5A.append(label_encoder.classes_[gold_label])\n",
    "\n",
    "result_frame5A = pd.DataFrame(pred_probabilities_5A*100, columns=label_encoder.classes_)\n",
    "\n",
    "result_frame5A['Chat']= list(tweets_dftest['Tweet'])\n",
    "result_frame5A['Prediction']=pred_labels_5A\n",
    "result_frame5A['Gold']=gold_labels_5A\n",
    "\n",
    "result_frame5A.to_csv(\"result_frame5A.csv\")\n",
    "result_frame5A.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04fc0ed-2cd8-45f1-bb50-af60f45675dd",
   "metadata": {},
   "source": [
    "### Filter B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68d1cb97-7e56-4d85-ac38-eb16ef61c782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determiner and pronouns {'half', '@capitalone', 'no', '@realdonaldtrump', 'tbh', 'üòä', '@eliroth', 'tho', 'thee', 'himself', 'the', 'boys', \"'em\", '@ritujai18874', 'they', 'em', 'either', 'itself', 'we', 'it', '@talktalkcare', 'its', 'an', 'our', 'these', 'each', '¬ª', 'u', '@messyourself', 'isthereahelplineforthis', 'some', '@xmaseveevil1', 'nj@latimes', '#behaviour', 'i', 'üòë', 'those', '@sarahb45', 'ourselves', 'lv', 'their', '@ryuredwings2', 'themselves', 'üçÇ', 'he', 'tvgirl', '@aefadul22', 'üí¶', 'this', 'ours', 'yours', 'myself', 'her', 'said!!!!\\\\nthey', 'every', 'stupid?that', 'yourself', 'that,\\\\ngives', '\\\\nindia', 'lt', \"naya'\\\\n\\\\n'i\", '@jbanks88', '#', 'that', \"'s\", 'blm', '@kristasaidthis', '@bbnicole', 'a', 'y', 'another', 'yhat', \"y'\", 'one', '@colinoccupantz', 'both', 'üòø', 'she', 'your', 'ios10', '@jankhambrams', '\\\\nmatt', '‚ú®', '@barbour', '@johnjharwood', '\\\\nwhat', '_', 'all', 'my', 'his', '@the', '@interception225', 'it.\\\\n#funny', 'theirs', 'any', '@jdegrom19', 'happy\\\\nshe', 'ya', '@adele', '@barackobama', '@digger_forum', \"\\\\n\\\\n'you\", 'üòÑ', '@space_gayz', 'd', '\\\\nso', 'neither', '@your', 'you', 'thy', '@rosie', 'mine'}\n",
      "Min_df 2\n"
     ]
    }
   ],
   "source": [
    "low_df_test_5B, DTandPRP_test_5B, clean_test_5B = \\\n",
    "remove_DT_PRP(2, test_data_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99bf09bb-37f5-435e-90bd-61dc3da66314",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of our matrix is: (3142, 200)\n",
      "Review 0 of 3142\n",
      "Review 1000 of 3142\n",
      "Review 2000 of 3142\n",
      "Review 3000 of 3142\n"
     ]
    }
   ],
   "source": [
    "testDataVecs_5B, test_5B_known_words, test_5B_unknown_words =\\\n",
    "getAvgFeatureVecs(clean_test_5B,\n",
    "                  word_embedding_model, \n",
    "                  index2word_set, \n",
    "                  num_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c35737b0-1f2e-49ae-a724-2b4789d3a537",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_5B = svm_linear_clf_5B.predict(testDataVecs_5B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d87f51e7-8f80-430b-84b7-637c060a5fc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'fear' 'joy' 'sadness']\n",
      "Embeddings SVM LINEAR: Tweets, Filter B\n",
      "Word embedding model used glove.twitter.27B.200d.txt\n",
      "Word mininum document frequency 2 ; DT PRP removed\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.673582  0.640789  0.656777       760\n",
      "           1   0.670647  0.677387  0.674000       995\n",
      "           2   0.664122  0.731092  0.696000       714\n",
      "           3   0.617834  0.576523  0.596464       673\n",
      "\n",
      "    accuracy                       0.659134      3142\n",
      "   macro avg   0.656546  0.656448  0.655810      3142\n",
      "weighted avg   0.658562  0.659134  0.658226      3142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_5B = classification_report(test_classes_5,y_pred_svm_5B,digits = 6)\n",
    "print(label_encoder.classes_)\n",
    "print('Embeddings SVM LINEAR: Tweets, Filter B')\n",
    "print('Word embedding model used', wordembeddings)\n",
    "print('Word mininum document frequency', min_df, \"; DT PRP removed\")\n",
    "print(report_5B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54d93a5d-5297-4303-9e06-db286738b5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix SVM, embeddings, Tweet, Filter B\n",
      "['anger' 'fear' 'joy' 'sadness']\n",
      "[[487 123  83  67]\n",
      " [113 674  95 113]\n",
      " [ 51  81 522  60]\n",
      " [ 72 127  86 388]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion matrix SVM, embeddings, Tweet, Filter B')\n",
    "print(label_encoder.classes_)\n",
    "print(sklearn.metrics.confusion_matrix(test_classes_5,y_pred_svm_5B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df179255-5c99-4a92-83ed-61b97996af47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>Chat</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.794562</td>\n",
       "      <td>16.824655</td>\n",
       "      <td>16.870062</td>\n",
       "      <td>20.510721</td>\n",
       "      <td>At the point today where if someone says somet...</td>\n",
       "      <td>anger</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.726648</td>\n",
       "      <td>24.080148</td>\n",
       "      <td>40.636461</td>\n",
       "      <td>2.556743</td>\n",
       "      <td>@CorningFootball  IT'S GAME DAY!!!!      T MIN...</td>\n",
       "      <td>joy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.988061</td>\n",
       "      <td>6.523268</td>\n",
       "      <td>7.924339</td>\n",
       "      <td>12.564331</td>\n",
       "      <td>This game has pissed me off more than any othe...</td>\n",
       "      <td>anger</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.944637</td>\n",
       "      <td>9.637974</td>\n",
       "      <td>54.143579</td>\n",
       "      <td>14.273811</td>\n",
       "      <td>@spamvicious I've just found out it's Candice ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.027014</td>\n",
       "      <td>34.681069</td>\n",
       "      <td>5.279899</td>\n",
       "      <td>16.012018</td>\n",
       "      <td>@moocowward @mrsajhargreaves @Melly77 @GaryBar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       anger       fear        joy    sadness  \\\n",
       "0  45.794562  16.824655  16.870062  20.510721   \n",
       "1  32.726648  24.080148  40.636461   2.556743   \n",
       "2  72.988061   6.523268   7.924339  12.564331   \n",
       "3  21.944637   9.637974  54.143579  14.273811   \n",
       "4  44.027014  34.681069   5.279899  16.012018   \n",
       "\n",
       "                                                Chat Prediction   Gold  \n",
       "0  At the point today where if someone says somet...      anger  anger  \n",
       "1  @CorningFootball  IT'S GAME DAY!!!!      T MIN...        joy  anger  \n",
       "2  This game has pissed me off more than any othe...      anger  anger  \n",
       "3  @spamvicious I've just found out it's Candice ...        joy  anger  \n",
       "4  @moocowward @mrsajhargreaves @Melly77 @GaryBar...      anger  anger  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probabilities_5B = svm_linear_clf_5B.predict_proba(testDataVecs_5B)\n",
    "\n",
    "pred_labels_5B = []\n",
    "for predicted_label in y_pred_svm_5B:\n",
    "    pred_labels_5B.append(label_encoder.classes_[predicted_label])\n",
    "\n",
    "gold_labels_5B = []\n",
    "for gold_label in test_classes_5:\n",
    "    gold_labels_5B.append(label_encoder.classes_[gold_label])\n",
    "\n",
    "result_frame5B = pd.DataFrame(pred_probabilities_5B*100, columns=label_encoder.classes_)\n",
    "\n",
    "result_frame5B['Chat']= list(tweets_dftest['Tweet'])\n",
    "result_frame5B['Prediction']=pred_labels_5B\n",
    "result_frame5B['Gold']=gold_labels_5B\n",
    "\n",
    "result_frame5B.to_csv(\"result_frame5B.csv\")\n",
    "result_frame5B.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
