{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c09547e-9a7d-4fb5-94ca-1e87df66694b",
   "metadata": {},
   "source": [
    "# 6. MELD+Tweets, Word-embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edd1c61-f66c-460b-931d-6e807aa337bc",
   "metadata": {},
   "source": [
    "## 6.1 Data preparation and filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c263dc4c-857f-4987-b60c-9073ae50c254",
   "metadata": {},
   "source": [
    "(a) Loading the MELD data and dropping the 'Neutral' label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64db58be-3ec7-4522-b90e-a5e9d0875098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-f4309fae7c64>:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  meld_dftrain['Utterance'] = meld_dftrain['Utterance'].str.replace(\"\\x92|\\x97|\\x91|\\x93|\\x94|\\x85\", \"'\")\n",
      "<ipython-input-1-f4309fae7c64>:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  meld_dftest['Utterance'] = meld_dftest['Utterance'].str.replace(\"\\x92|\\x97|\\x91|\\x93|\\x94|\\x85\", \"'\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filepath = './data/MELD/train_sent_emo.csv'\n",
    "meld_dftrain = pd.read_csv(filepath)\n",
    "meld_dftrain['Utterance'] = meld_dftrain['Utterance'].str.replace(\"\\x92|\\x97|\\x91|\\x93|\\x94|\\x85\", \"'\")\n",
    "\n",
    "filepath = './data/MELD/test_sent_emo.csv'\n",
    "meld_dftest = pd.read_csv(filepath)\n",
    "meld_dftest['Utterance'] = meld_dftest['Utterance'].str.replace(\"\\x92|\\x97|\\x91|\\x93|\\x94|\\x85\", \"'\")\n",
    "\n",
    "meld_dftrain = meld_dftrain.set_index(\"Emotion\", drop=False)\n",
    "meld_dftrain = meld_dftrain.drop(\"neutral\", axis=0)\n",
    "\n",
    "meld_dftest = meld_dftest.set_index(\"Emotion\", drop=False)\n",
    "meld_dftest = meld_dftest.drop(\"neutral\", axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0225d3-4797-4cfb-937f-f4eaf4ae658a",
   "metadata": {},
   "source": [
    "(b) Loading the Tweets data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6330b1bd-208e-4384-89dc-79dd449da4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'data/wassa/training/all.train.tsv'\n",
    "tweets_dftrain = pd.read_csv(filepath, sep='\\t')\n",
    "\n",
    "filepath = 'data/wassa/testing/all.test.tsv'\n",
    "tweets_dftest = pd.read_csv(filepath, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eaf9f2-3123-4715-aabe-4982b069d980",
   "metadata": {
    "tags": []
   },
   "source": [
    "(c) Combining the two data sets\n",
    "  -  Rename the following axes the same names:\n",
    "      -  MELD  \"Sr No.\": \"ID\", \"Utterance\": \"Sent\"\n",
    "      -  Tweets  \"Tweet\": \"Sent\", \"Label\": \"Emotion\"\n",
    "  - Concatenate the two dataframes in a way that their IDs, sentences and labels are aligned. Two additional keys: \"MELD\" and \"Tweets\" are added to identify from where a particular entry is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76ea1956-dc15-4867-abe9-655df09832bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change index of MELD back to number sequence\n",
    "meld_dftrain = meld_dftrain.set_index(pd.Series(list(range(len(meld_dftrain)))))\n",
    "meld_dftest = meld_dftest.set_index(pd.Series(list(range(len(meld_dftest)))))\n",
    "\n",
    "# Training data\n",
    "meld_dftrain = meld_dftrain.rename(columns={\"Sr No.\": \"ID\", \"Utterance\": \"Sent\"})\n",
    "tweets_dftrain = tweets_dftrain.rename(columns={\"Tweet\": \"Sent\", \"Label\": \"Emotion\"})\n",
    "combined_dftrain = pd.concat([meld_dftrain, tweets_dftrain], keys=['MELD', 'Tweets'])\n",
    "\n",
    "# Test data\n",
    "meld_dftest = meld_dftest.rename(columns={\"Sr No.\": \"ID\", \"Utterance\": \"Sent\"})\n",
    "tweets_dftest = tweets_dftest.rename(columns={\"Tweet\": \"Sent\", \"Label\": \"Emotion\"})\n",
    "combined_dftest = pd.concat([meld_dftest, tweets_dftest], keys=['MELD', 'Tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "433385ca-c15a-4442-ae24-43391c6d4169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sent</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>surprise</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:34,452</td>\n",
       "      <td>00:16:40,917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>No don't I beg of you!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>fear</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:17:02,856</td>\n",
       "      <td>00:17:04,858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>Really?!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>surprise</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:17:13,491</td>\n",
       "      <td>00:17:16,536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>But then who? The waitress I went out with las...</td>\n",
       "      <td>Joey</td>\n",
       "      <td>surprise</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>00:36:40,364</td>\n",
       "      <td>00:36:42,824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>You know? Forget it!</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>sadness</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>00:36:44,368</td>\n",
       "      <td>00:36:46,578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               Sent   Speaker   Emotion  \\\n",
       "0   5                             My duties?  All right.  Chandler  surprise   \n",
       "1  11                             No don't I beg of you!  Chandler      fear   \n",
       "2  13                                           Really?!  Chandler  surprise   \n",
       "3  15  But then who? The waitress I went out with las...      Joey  surprise   \n",
       "4  16                               You know? Forget it!    Rachel   sadness   \n",
       "\n",
       "  Sentiment  Dialogue_ID  Utterance_ID  Season  Episode     StartTime  \\\n",
       "0  positive            0             4       8       21  00:16:34,452   \n",
       "1  negative            0            10       8       21  00:17:02,856   \n",
       "2  positive            0            12       8       21  00:17:13,491   \n",
       "3  negative            1             0       9       23  00:36:40,364   \n",
       "4  negative            1             1       9       23  00:36:44,368   \n",
       "\n",
       "        EndTime  \n",
       "0  00:16:40,917  \n",
       "1  00:17:04,858  \n",
       "2  00:17:16,536  \n",
       "3  00:36:42,824  \n",
       "4  00:36:46,578  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the changes\n",
    "meld_dftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d733a9e2-8693-4254-aea5-4e379881bb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sent</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                               Sent Emotion  Score\n",
       "0  10000  How the fu*k! Who the heck! moved my fridge!.....   anger  0.938\n",
       "1  10001  So my Indian Uber driver just called someone t...   anger  0.896\n",
       "2  10002  @DPD_UK I asked for my parcel to be delivered ...   anger  0.896\n",
       "3  10003  so ef whichever butt wipe pulled the fire alar...   anger  0.896\n",
       "4  10004  Don't join @BTCare they put the phone down on ...   anger  0.896"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_dftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d33d045e-79eb-40d2-9566-82a959377d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sent</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">MELD</th>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>surprise</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>00:16:34,452</td>\n",
       "      <td>00:16:40,917</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>No don't I beg of you!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>fear</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>00:17:02,856</td>\n",
       "      <td>00:17:04,858</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>Really?!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>surprise</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>00:17:13,491</td>\n",
       "      <td>00:17:16,536</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>But then who? The waitress I went out with las...</td>\n",
       "      <td>Joey</td>\n",
       "      <td>surprise</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>00:36:40,364</td>\n",
       "      <td>00:36:42,824</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>You know? Forget it!</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>sadness</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>00:36:44,368</td>\n",
       "      <td>00:36:46,578</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               Sent   Speaker  \\\n",
       "MELD 0   5                             My duties?  All right.  Chandler   \n",
       "     1  11                             No don't I beg of you!  Chandler   \n",
       "     2  13                                           Really?!  Chandler   \n",
       "     3  15  But then who? The waitress I went out with las...      Joey   \n",
       "     4  16                               You know? Forget it!    Rachel   \n",
       "\n",
       "         Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n",
       "MELD 0  surprise  positive          0.0           4.0     8.0     21.0   \n",
       "     1      fear  negative          0.0          10.0     8.0     21.0   \n",
       "     2  surprise  positive          0.0          12.0     8.0     21.0   \n",
       "     3  surprise  negative          1.0           0.0     9.0     23.0   \n",
       "     4   sadness  negative          1.0           1.0     9.0     23.0   \n",
       "\n",
       "           StartTime       EndTime  Score  \n",
       "MELD 0  00:16:34,452  00:16:40,917    NaN  \n",
       "     1  00:17:02,856  00:17:04,858    NaN  \n",
       "     2  00:17:13,491  00:17:16,536    NaN  \n",
       "     3  00:36:40,364  00:36:42,824    NaN  \n",
       "     4  00:36:44,368  00:36:46,578    NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7917a7a-9a88-4c56-a057-8f0177b71b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sent</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Tweets</th>\n",
       "      <th>3608</th>\n",
       "      <td>40781</td>\n",
       "      <td>@VivienLloyd Thank you so much! Just home - st...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sadness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3609</th>\n",
       "      <td>40782</td>\n",
       "      <td>Just put the winter duvet on ‚òÉÔ∏è‚ùÑÔ∏èüå¨‚òîÔ∏è</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sadness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3610</th>\n",
       "      <td>40783</td>\n",
       "      <td>@SilkInSide @TommyJoeRatliff that's so pretty!...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sadness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>40784</td>\n",
       "      <td>@BluesfestByron second artist announcement loo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sadness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>40785</td>\n",
       "      <td>I can literally eat creamy pesto pasta topped ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sadness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID                                               Sent Speaker  \\\n",
       "Tweets 3608  40781  @VivienLloyd Thank you so much! Just home - st...     NaN   \n",
       "       3609  40782              Just put the winter duvet on ‚òÉÔ∏è‚ùÑÔ∏èüå¨‚òîÔ∏è      NaN   \n",
       "       3610  40783  @SilkInSide @TommyJoeRatliff that's so pretty!...     NaN   \n",
       "       3611  40784  @BluesfestByron second artist announcement loo...     NaN   \n",
       "       3612  40785  I can literally eat creamy pesto pasta topped ...     NaN   \n",
       "\n",
       "             Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n",
       "Tweets 3608  sadness       NaN          NaN           NaN     NaN      NaN   \n",
       "       3609  sadness       NaN          NaN           NaN     NaN      NaN   \n",
       "       3610  sadness       NaN          NaN           NaN     NaN      NaN   \n",
       "       3611  sadness       NaN          NaN           NaN     NaN      NaN   \n",
       "       3612  sadness       NaN          NaN           NaN     NaN      NaN   \n",
       "\n",
       "            StartTime EndTime  Score  \n",
       "Tweets 3608       NaN     NaN  0.104  \n",
       "       3609       NaN     NaN  0.104  \n",
       "       3610       NaN     NaN  0.088  \n",
       "       3611       NaN     NaN  0.083  \n",
       "       3612       NaN     NaN  0.083  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dftrain.tail()\n",
    "\n",
    "# The data sets are concatenated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630744b9-25ef-4935-ab7f-fb50e78f0531",
   "metadata": {},
   "source": [
    "(d) Tokenizing and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c12fa2c1-42d4-4a31-8a5f-90ee90f9caad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Using spaCy to tokenize the sentences\n",
    "training_data_6 = [nlp(sent) for sent in list(combined_dftrain['Sent'])]\n",
    "training_labels_6 = list(combined_dftrain['Emotion'])\n",
    "\n",
    "test_data_6 = [nlp(sent) for sent in list(combined_dftest['Sent'])]\n",
    "test_labels_6 = list(combined_dftest['Emotion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a29853-de60-4110-99d9-4b5745389cb4",
   "metadata": {},
   "source": [
    "### Filter A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4686137-7d97-4622-b1ba-047b6b0c9d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_df 2\n",
      "Max_df 889\n",
      "Rare words with low df =  5972 words. Examples:  ['@susansarandon', '@ren102e906', '@darwinwaterson', '\\\\nhi', 'rapidly', 'territorial', 'hentai', 'furrie', '@tombrodude', '36', 'emotionalhedge', 'mansfieldhour', 'cadres', 'best', 'us\\\\ni', 'irrefutable', '@annalisewrobel', '@uber_rsa', '@pandaflo22', 'keeping']\n",
      "Stop words with high df: {'!', 'have', '.', 'it', '?', 'of', 'be', 'do', 'my', 'and', '#', 'a', 'the', 'i', 'you', \"n't\", 'to', ',', 'that'}\n",
      "Size of the rest vocab: 4915\n",
      "Samples: [['just', 'coffee', 'where', 'we', 'gon', 'na', 'hang', 'out', 'now'], ['got'], [], ['um', '-', 'mm', 'yeah', 'right'], ['oh', 'god', 'oh', 'god', 'poor', 'monica'], ['what', 'what', 'what'], ['what'], ['he', 'think', 'monica', 'empty', 'she', 'empty', 'vase'], ['oh', 'totally', 'oh', 'god', 'oh', 'she', 'seem', 'so', 'happy', 'too'], ['hey']]\n"
     ]
    }
   ],
   "source": [
    "from utils import low_high_mid_df\n",
    "min_df = 2\n",
    "max_df = len(training_data_6)//10\n",
    "\n",
    "low_df, high_df, clean6A = low_high_mid_df(min_df, max_df, training_data_6)\n",
    "\n",
    "print(\"Rare words with low df = \", len(low_df), \"words. Examples: \", list(low_df)[:20])\n",
    "print(\"Stop words with high df:\", high_df)\n",
    "vocab_6A = set()\n",
    "for sent in clean6A:\n",
    "    for t in sent:\n",
    "        vocab_6A.add(t)\n",
    "print(\"Size of the rest vocab:\", len(vocab_6A))\n",
    "print(\"Samples:\", clean6A[10:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb8dec7-a76b-4310-b988-473c38505150",
   "metadata": {},
   "source": [
    "### Filter B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e446e76-b2bc-462f-9436-33c93becb0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determiner and pronouns {\"y'\", '@reyesaverie', '@melissajoyrd', \"it's\", '@weebtard', 'üçÅ', '@british_airways', 'it', 'mine', '\\\\n#you', 'any', 'each', 'this', 'ba', 'eagles.\\\\nthey', 'yours', 'strength.\\\\nthey', 'üëÖ', '\\\\nit', ':)', 'they', 'its', '_', \"'em\", '\\\\n\\\\nother', '‚Äôs', 'don‚Äôt', \"you're'you\", 'an', 'those', 'd', '@mhchat', 'herself', \"that'you\", '\\\\nimagine', '@ntfc', 'himself', '@adsbyflaherty', \"film'that\", 'tbh', 'my', 'üêÆ', 'üòß', \"up'i\", '\\uf62b', 'xx', 'memphis', 'also-', '@m_t_f_72', 'i', '‚ù§', 'yourself', 'tho', \"i'i'm\", 'that?s', '@kevincanwaitcbs', 'near,\\\\nthe', 'her', '@rowillfindyou', 'ours', 'themselves', '@relaqss', 'his', 'bridgetjonesbaby', 'another', 'either', 'some', \"'s\", 'em', '@fra93_bruno', 'your', '@themathofyou', 'their', '@its.finfin', 'üêà', '@snub23', 'üò°', '#', 'no', \"i'y'know\", 'hbu', \"was'the\", 'the', 'both', 'our', '\\\\n\\\\nsam', '@blackeyed_susie', '@missmeliss465', 'scarred,\\\\nthis', 'ek', \"i'm\", 'one', 'jut', '@sargon_of_akkad', 'ty', 'all', 'the-', '@smshow', 'isthereahelplineforthis', 'myself', \"underwear'you\", 'itself', \"i'll\", \"mean'i\", 'hers', 'ya', '@neyaphemmaster', 'thy', 'i-', 'ourselves', 'üòä', '@ryyyshh', 'every', 'oldham\\\\nnext', 'u', 'a', 'he', '‚ú®', 'she', \"you're\", 'you', 'tux', 'y', 'these', 'we', \"fact'yes\", 'that', 'neither', 'n'}\n",
      "Min_df 2\n",
      "Rare words with low df =  5939 words. Examples: ['@susansarandon', '@ren102e906', '@darwinwaterson', '\\\\nhi', 'rapidly', 'territorial', 'hentai', 'furrie', '@tombrodude', '36', 'emotionalhedge', 'mansfieldhour', 'cadres', 'best', 'us\\\\ni', 'irrefutable', '@annalisewrobel', '@uber_rsa', '@pandaflo22', 'keeping']\n",
      "Size of the rest vocab: 4887\n",
      "Samples: [['just', 'coffee', '!', 'where', 'be', 'gon', 'na', 'hang', 'out', 'now', '?'], ['got', '.'], ['!'], ['um', '-', 'mm', ',', 'yeah', 'right', '!'], ['oh', 'my', 'god', ',', 'oh', 'my', 'god', '!', 'poor', 'monica', '!'], ['what', ',', 'what', ',', 'what', '?', '!'], ['what', '?', '!'], ['think', 'monica', 'be', 'empty', ',', 'be', 'empty', 'vase', '!'], ['oh', ',', 'totally', '.', 'oh', ',', 'god', ',', 'oh', ',', 'seem', 'so', 'happy', 'too', '.'], ['hey', '!']]\n"
     ]
    }
   ],
   "source": [
    "from utils import remove_DT_PRP\n",
    "\n",
    "min_df = 2\n",
    "\n",
    "low_df, DTandPRP_tok, clean6B = remove_DT_PRP(min_df, training_data_6)\n",
    "\n",
    "print(\"Rare words with low df = \", len(low_df), \"words. Examples:\", list(low_df)[:20])\n",
    "vocab_6B = set()\n",
    "for sent in clean6B:\n",
    "    for t in sent:\n",
    "        vocab_6B.add(t)\n",
    "print(\"Size of the rest vocab:\", len(vocab_6B))\n",
    "print(\"Samples:\", clean6B[10:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8e959f-6578-46b0-8ea4-6535ef86951d",
   "metadata": {},
   "source": [
    "## 5.2 Word-embedding model and training the classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbddd28b-c267-4d97-87e3-4730986673e4",
   "metadata": {},
   "source": [
    "(a) Encoding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a10698ca-a48c-4fa3-92e2-011c201be758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(training_labels_6+test_labels_6)\n",
    "print(list(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "888754b2-aabd-4efc-ad33-3eb27af00ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 2 5 5 4]\n",
      "['surprise', 'fear', 'surprise', 'surprise', 'sadness']\n",
      "['My duties?  All right.', \"No don't I beg of you!\", 'Really?!', 'But then who? The waitress I went out with last month?', 'You know? Forget it!']\n"
     ]
    }
   ],
   "source": [
    "training_classes = label_encoder.transform(training_labels_6)\n",
    "print(training_classes[:5])\n",
    "print(list(combined_dftrain['Emotion'])[:5])\n",
    "print(list(combined_dftrain['Sent'])[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b930556e-7f9b-4083-9d64-7b401f123c8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "(b) Loading the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0161bbeb-21a3-4241-8805-e66d104dc0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-dc66f279bafc>:12: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  _ = glove2word2vec(glove_file, tmp_file)\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "from os import path\n",
    "\n",
    "wordembeddings=\"glove.twitter.27B.200d.txt\"\n",
    "glove_file = datapath(path.abspath('../glove/glove.twitter.27B.200d.txt'))\n",
    "\n",
    "# Create a word2vec model from the Glove text data\n",
    "tmp_file = get_tmpfile(\"test_word2vec.txt\")\n",
    "_ = glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "word_embedding_model = KeyedVectors.load_word2vec_format(tmp_file)\n",
    "\n",
    "# Dimensions set to 200.\n",
    "num_features = 200\n",
    "\n",
    "# Converting Index2Word\n",
    "index2word_set = set(word_embedding_model.index_to_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda92b8e-35dd-457f-a1be-71f72efb7895",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Filter A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "892d7d42-bd1b-4287-aaae-0c76ef32848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of our matrix is: (8892, 200)\n",
      "Review 0 of 8892\n",
      "Review 1000 of 8892\n",
      "Review 2000 of 8892\n",
      "Review 3000 of 8892\n",
      "Review 4000 of 8892\n",
      "Review 5000 of 8892\n",
      "Review 6000 of 8892\n",
      "Review 7000 of 8892\n",
      "Review 8000 of 8892\n"
     ]
    }
   ],
   "source": [
    "from utils import featureVecMethod, getAvgFeatureVecs\n",
    "\n",
    "trainFeatureVecs_6A, embedding_words_6A, no_embedding_words_6A = \\\n",
    "getAvgFeatureVecs(clean6A,\n",
    "                  word_embedding_model, \n",
    "                  index2word_set, \n",
    "                  num_features\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "649db7f7-65f6-4c0b-9b2d-95915ec15820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all', 'right', 'no', 'really', 'but', 'then', 'who', 'waitress', 'go', 'out', 'with', 'last', 'month', 'know', 'forget', 'no', '-', 'no', '-', 'no', '-', 'no', 'no', 'who', 'who', 'talk', 'about', 'no', '-', '-', '-', 'actually', 'know', 'ever', 'chris', 'say', 'they', 'close', 'down', 'bar', 'no', 'way', 'just', 'coffee', 'where', 'we', 'gon', 'na', 'hang', 'out']\n",
      "\n",
      "[' ', \"y'know\", '...', '...', ' ', ' ', ' ', \"y'know\", ' ', '15', '...', '...', '...', ' ', ' ', '...', ' ', ' ', ' ', \"i'm\", ' ', ' ', \"y'know\", ' ', ' ', ' ', ' ', '...', '  ', ' ', \"nothin'\", \"nothin'\", \"it's\", \"y'know\", '  ', '...', ' ', ' ', ' ', ' ', ' ', '  ', \"y'know\", '...', ' ', ' ', ' ', ' ', ' ', '...']\n"
     ]
    }
   ],
   "source": [
    "print(embedding_words_6A[:50])\n",
    "print()\n",
    "print(no_embedding_words_6A[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5c43afe-d127-4623-81f9-16b298bd1569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=LinearSVC(max_iter=2000), cv=10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "linear_model = svm.LinearSVC(max_iter=2000)\n",
    "svm_linear_clf_6A = CalibratedClassifierCV(linear_model , method='sigmoid', cv=10)\n",
    "\n",
    "svm_linear_clf_6A.fit(trainFeatureVecs_6A, training_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87cd4e8-f0b2-478e-9c86-9f3970061820",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Filter B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a32f6be2-c67f-4071-ad1d-88263065a6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of our matrix is: (8892, 200)\n",
      "Review 0 of 8892\n",
      "Review 1000 of 8892\n",
      "Review 2000 of 8892\n",
      "Review 3000 of 8892\n",
      "Review 4000 of 8892\n",
      "Review 5000 of 8892\n",
      "Review 6000 of 8892\n",
      "Review 7000 of 8892\n",
      "Review 8000 of 8892\n"
     ]
    }
   ],
   "source": [
    "trainFeatureVecs_6B, embedding_words_6B, no_embedding_words_6B = \\\n",
    "getAvgFeatureVecs(clean6B,\n",
    "                  word_embedding_model, \n",
    "                  index2word_set, \n",
    "                  num_features\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "003e7956-8227-4186-a875-aa87a4e235ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['?', 'all', 'right', '.', 'no', 'do', \"n't\", 'of', '!', 'really', '?', '!', 'but', 'then', 'who', '?', 'waitress', 'go', 'out', 'with', 'last', 'month', '?', 'know', '?', 'forget', '!', 'no', '-', '-', 'no', '-', 'no', ',', 'no', '!', 'who', ',', 'who', 'be', 'talk', 'about', '?', 'no', ',', 'i', '-', '-', 'i', '-']\n",
      "\n",
      "[' ', \"y'know\", '...', '...', ' ', ' ', ' ', \"y'know\", ' ', '15', '...', '...', '...', ' ', ' ', '...', ' ', ' ', ' ', \"i'm\", ' ', ' ', \"y'know\", ' ', ' ', ' ', ' ', '...', '  ', ' ', \"nothin'\", \"nothin'\", \"y'know\", '  ', '...', ' ', ' ', ' ', ' ', ' ', '  ', \"y'know\", '...', ' ', ' ', ' ', ' ', ' ', '...', 'goodacre']\n"
     ]
    }
   ],
   "source": [
    "print(embedding_words_6B[:50])\n",
    "print()\n",
    "print(no_embedding_words_6B[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c27c8747-5598-4bc9-9470-144e34d5b74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=LinearSVC(max_iter=2000), cv=10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = svm.LinearSVC(max_iter=2000)\n",
    "svm_linear_clf_6B = CalibratedClassifierCV(linear_model , method='sigmoid', cv=10)\n",
    "\n",
    "svm_linear_clf_6B.fit(trainFeatureVecs_6B, training_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4354c311-73ef-4a7b-847a-8fa19006dd7e",
   "metadata": {},
   "source": [
    "## 5.3 Predicting the test data and results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2683e951-d74f-4a02-b512-ce94c47c224e",
   "metadata": {},
   "source": [
    "Encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f469c20b-ecf6-4644-9644-e4e2d84b64c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 3 3 3]\n",
      "['surprise', 'anger', 'joy', 'joy', 'joy']\n",
      "[\"Why do all you're coffee mugs have numbers on the bottom?\", \"Oh. That's so Monica can keep track. That way if one on them is missing, she can be like, 'Where's number 27?!'\", 'Push!', \"Push 'em out, push 'em out, harder, harder.\", \"Push 'em out, push 'em out, way out!\"]\n"
     ]
    }
   ],
   "source": [
    "test_classes_6 = label_encoder.transform(test_labels_6)\n",
    "print(test_classes_6[:5])\n",
    "print(list(combined_dftest['Emotion'])[:5])\n",
    "print(list(combined_dftest['Sent'])[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da5d2da-cc44-45de-abbe-83f209103b18",
   "metadata": {},
   "source": [
    "### Filter A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc67d7-ddd5-4aa0-8cab-c7fa7b4c62a8",
   "metadata": {},
   "source": [
    "(a) Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a51ca46-cf3a-40d7-85e8-976f5ff67951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_df 2\n",
      "Max_df 449\n"
     ]
    }
   ],
   "source": [
    "max_df_test = len(test_data_6)//10\n",
    "\n",
    "low_df_test_6A, high_df_test_6A, test_mid_df_6A = \\\n",
    "low_high_mid_df(2, max_df_test, test_data_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60e2e5de-4038-4c18-ab34-3da97b53708c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'!', 'have', '.', 'it', '?', 'of', 'be', 'do', 'on', 'my', 'and', '#', 'a', 'the', 'i', 'you', \"n't\", 'in', 'to', ',', 'that'}\n"
     ]
    }
   ],
   "source": [
    "print(high_df_test_6A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e92cd7c-bcb4-436c-be20-a8f24fb8a4cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of our matrix is: (4496, 200)\n",
      "Review 0 of 4496\n",
      "Review 1000 of 4496\n",
      "Review 2000 of 4496\n",
      "Review 3000 of 4496\n",
      "Review 4000 of 4496\n"
     ]
    }
   ],
   "source": [
    "testDataVecs_6A, test_6A_known_words, test_6A_unknown_words =\\\n",
    "getAvgFeatureVecs(test_mid_df_6A,\n",
    "                  word_embedding_model, \n",
    "                  index2word_set, \n",
    "                  num_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6522eaf-1a74-4ac2-82d2-629f328b280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_6A = svm_linear_clf_6A.predict(testDataVecs_6A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fec3ee5-28e9-4410-92d0-7b2c9e76a16a",
   "metadata": {},
   "source": [
    "(b) Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f990db4-ea96-4aad-83ff-08c120bf626f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'disgust' 'fear' 'joy' 'sadness' 'surprise']\n",
      "Embeddings SVM LINEAR: MELD+Tweets, Filter A\n",
      "Word embedding model used glove.twitter.27B.200d.txt\n",
      "Word mininum document frequency 2 : max: 449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.538326  0.552941  0.545536      1105\n",
      "           1   1.000000  0.014706  0.028986        68\n",
      "           2   0.674830  0.474641  0.557303      1045\n",
      "           3   0.501416  0.793011  0.614370      1116\n",
      "           4   0.587922  0.375709  0.458449       881\n",
      "           5   0.474747  0.501779  0.487889       281\n",
      "\n",
      "    accuracy                       0.548265      4496\n",
      "   macro avg   0.629540  0.452131  0.448755      4496\n",
      "weighted avg   0.573619  0.548265  0.536877      4496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Evaluating and analyzing the result\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report_6A = classification_report(test_classes_6,y_pred_svm_6A,digits = 6)\n",
    "print(label_encoder.classes_)\n",
    "print('Embeddings SVM LINEAR: MELD+Tweets, Filter A')\n",
    "print('Word embedding model used', wordembeddings)\n",
    "print('Word mininum document frequency', min_df, \": max:\", max_df_test)\n",
    "print(report_6A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0c5fc9a-8dcb-40ee-9f09-c750642d13c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix SVM, embeddings, MELD+Tweets, Filter A\n",
      "['anger' 'disgust' 'fear' 'joy' 'sadness' 'surprise']\n",
      "[[611   0  82 289  67  56]\n",
      " [ 24   1   2  25   6  10]\n",
      " [215   0 496 218  92  24]\n",
      " [ 89   0  53 885  53  36]\n",
      " [165   0  95 260 331  30]\n",
      " [ 31   0   7  88  14 141]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print('Confusion matrix SVM, embeddings, MELD+Tweets, Filter A')\n",
    "print(label_encoder.classes_)\n",
    "print(sklearn.metrics.confusion_matrix(test_classes_6,y_pred_svm_6A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a3e2224-9ead-4af4-91a7-3df7c797cdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>Chat</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.199536</td>\n",
       "      <td>5.170501</td>\n",
       "      <td>3.184909</td>\n",
       "      <td>32.818911</td>\n",
       "      <td>19.760709</td>\n",
       "      <td>13.865433</td>\n",
       "      <td>Why do all you're coffee mugs have numbers on ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.631798</td>\n",
       "      <td>3.001689</td>\n",
       "      <td>9.181429</td>\n",
       "      <td>39.802757</td>\n",
       "      <td>18.725642</td>\n",
       "      <td>11.656686</td>\n",
       "      <td>Oh. That's so Monica can keep track. That way ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.406057</td>\n",
       "      <td>2.345162</td>\n",
       "      <td>47.325382</td>\n",
       "      <td>13.044321</td>\n",
       "      <td>3.426252</td>\n",
       "      <td>8.452827</td>\n",
       "      <td>Push!</td>\n",
       "      <td>fear</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44.771639</td>\n",
       "      <td>2.060420</td>\n",
       "      <td>5.770728</td>\n",
       "      <td>26.156729</td>\n",
       "      <td>18.202186</td>\n",
       "      <td>3.038299</td>\n",
       "      <td>Push 'em out, push 'em out, harder, harder.</td>\n",
       "      <td>anger</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.072344</td>\n",
       "      <td>3.120442</td>\n",
       "      <td>9.699568</td>\n",
       "      <td>29.864994</td>\n",
       "      <td>8.918786</td>\n",
       "      <td>2.323866</td>\n",
       "      <td>Push 'em out, push 'em out, way out!</td>\n",
       "      <td>anger</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       anger   disgust       fear        joy    sadness   surprise  \\\n",
       "0  25.199536  5.170501   3.184909  32.818911  19.760709  13.865433   \n",
       "1  17.631798  3.001689   9.181429  39.802757  18.725642  11.656686   \n",
       "2  25.406057  2.345162  47.325382  13.044321   3.426252   8.452827   \n",
       "3  44.771639  2.060420   5.770728  26.156729  18.202186   3.038299   \n",
       "4  46.072344  3.120442   9.699568  29.864994   8.918786   2.323866   \n",
       "\n",
       "                                                Chat Prediction      Gold  \n",
       "0  Why do all you're coffee mugs have numbers on ...        joy  surprise  \n",
       "1  Oh. That's so Monica can keep track. That way ...        joy     anger  \n",
       "2                                              Push!       fear       joy  \n",
       "3        Push 'em out, push 'em out, harder, harder.      anger       joy  \n",
       "4               Push 'em out, push 'em out, way out!      anger       joy  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probabilities_6A = svm_linear_clf_6A.predict_proba(testDataVecs_6A)\n",
    "\n",
    "pred_labels_6A = []\n",
    "for predicted_label in y_pred_svm_6A:\n",
    "    pred_labels_6A.append(label_encoder.classes_[predicted_label])\n",
    "\n",
    "gold_labels_6A = []\n",
    "for gold_label in test_classes_6:\n",
    "    gold_labels_6A.append(label_encoder.classes_[gold_label])\n",
    "\n",
    "result_frame6A = pd.DataFrame(pred_probabilities_6A*100, columns=label_encoder.classes_)\n",
    "\n",
    "result_frame6A['Chat']= list(combined_dftest['Sent'])\n",
    "result_frame6A['Prediction']=pred_labels_6A\n",
    "result_frame6A['Gold']=gold_labels_6A\n",
    "\n",
    "result_frame6A.to_csv(\"result_frame6A.csv\")\n",
    "result_frame6A.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04fc0ed-2cd8-45f1-bb50-af60f45675dd",
   "metadata": {},
   "source": [
    "### Filter B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68d1cb97-7e56-4d85-ac38-eb16ef61c782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determiner and pronouns {'@jdegrom19', \"y'\", '@jbanks88', \"i'i\", 'it', 'mine', '\\\\nwhat', 'any', 'each', 'this', 'yours', '@adele', \"they're\", '@colinoccupantz', \"\\\\n\\\\n'you\", '@eliroth', 'ios10', 'nj@latimes', '\\\\nso', 'stupid?that', 'they', 'its', '_', \"'em\", '@ritujai18874', '#behaviour', '@barbour', '@talktalkcare', '‚Äôs', '@space_gayz', '@your', 'an', 'those', 'd', '@johnjharwood', '@the', 'said!!!!\\\\nthey', 'thee', 'himself', '@xmaseveevil1', '\\\\nindia', 'tbh', 'my', '@ryuredwings2', 'üòÑ', 'i', 'yourself', '@kristasaidthis', 'tho', '@messyourself', '@aefadul22', '¬ª', 'blm', '@barackobama', 'that,\\\\ngives', 'her', 'ours', 'themselves', 'his', 'üçÇ', 'either', 'another', 'some', 'happy\\\\nshe', \"'s\", 'em', 'your', \"naya'\\\\n\\\\n'i\", 'their', 'half', '@digger_forum', 'üòë', 'lt', 'it.\\\\n#funny', '#', 'no', '\\\\nmatt', 'the', 'our', 'both', 'tvgirl', 'üí¶', \"i'm\", 'one', '@realdonaldtrump', 'all', '@sarahb45', 'isthereahelplineforthis', 'myself', 'üòø', '@jankhambrams', 'itself', '@bbnicole', 'boys', 'hers', 'ya', 'thy', 'lv', 'ourselves', 'üòä', '@rosie', 'every', 'u', 'a', \"my'this\", '@interception225', 'he', '‚ú®', 'she', 'theirs', \"you're\", 'you', '@capitalone', 'y', 'yhat', 'these', 'we', 'that', 'neither'}\n",
      "Min_df 2\n"
     ]
    }
   ],
   "source": [
    "low_df_test_6B, DTandPRP_test_6B, clean_test_6B = \\\n",
    "remove_DT_PRP(2, test_data_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99bf09bb-37f5-435e-90bd-61dc3da66314",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of our matrix is: (4496, 200)\n",
      "Review 0 of 4496\n",
      "Review 1000 of 4496\n",
      "Review 2000 of 4496\n",
      "Review 3000 of 4496\n",
      "Review 4000 of 4496\n"
     ]
    }
   ],
   "source": [
    "testDataVecs_6B, test_6B_known_words, test_6B_unknown_words =\\\n",
    "getAvgFeatureVecs(clean_test_6B,\n",
    "                  word_embedding_model, \n",
    "                  index2word_set, \n",
    "                  num_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c35737b0-1f2e-49ae-a724-2b4789d3a537",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_6B = svm_linear_clf_6B.predict(testDataVecs_6B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d87f51e7-8f80-430b-84b7-637c060a5fc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'disgust' 'fear' 'joy' 'sadness' 'surprise']\n",
      "Embeddings SVM LINEAR: MELD+Tweets, Filter B\n",
      "Word embedding model used glove.twitter.27B.200d.txt\n",
      "Word mininum document frequency 2 ; DT PRP removed\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.584721  0.540271  0.561618      1105\n",
      "           1   0.666667  0.029412  0.056338        68\n",
      "           2   0.647123  0.570335  0.606307      1045\n",
      "           3   0.540963  0.775090  0.637201      1116\n",
      "           4   0.593060  0.426788  0.496370       881\n",
      "           5   0.537736  0.608541  0.570952       281\n",
      "\n",
      "    accuracy                       0.579849      4496\n",
      "   macro avg   0.595045  0.491739  0.488131      4496\n",
      "weighted avg   0.588300  0.579849  0.570922      4496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_6B = classification_report(test_classes_6,y_pred_svm_6B,digits = 6)\n",
    "print(label_encoder.classes_)\n",
    "print('Embeddings SVM LINEAR: MELD+Tweets, Filter B')\n",
    "print('Word embedding model used', wordembeddings)\n",
    "print('Word mininum document frequency', min_df, \"; DT PRP removed\")\n",
    "print(report_6B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54d93a5d-5297-4303-9e06-db286738b5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix SVM, embeddings, MELD+Tweet, Filter B\n",
      "['anger' 'disgust' 'fear' 'joy' 'sadness' 'surprise']\n",
      "[[597   1 108 258  81  60]\n",
      " [ 19   2   2  28  10   7]\n",
      " [168   0 596 158 100  23]\n",
      " [ 85   0  72 865  62  32]\n",
      " [131   0 137 212 376  25]\n",
      " [ 21   0   6  78   5 171]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion matrix SVM, embeddings, MELD+Tweet, Filter B')\n",
    "print(label_encoder.classes_)\n",
    "print(sklearn.metrics.confusion_matrix(test_classes_6,y_pred_svm_6B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df179255-5c99-4a92-83ed-61b97996af47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>Chat</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.369358</td>\n",
       "      <td>2.737392</td>\n",
       "      <td>2.352420</td>\n",
       "      <td>11.380595</td>\n",
       "      <td>28.313076</td>\n",
       "      <td>29.847160</td>\n",
       "      <td>Why do all you're coffee mugs have numbers on ...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.117586</td>\n",
       "      <td>3.517425</td>\n",
       "      <td>7.371107</td>\n",
       "      <td>42.598438</td>\n",
       "      <td>19.432031</td>\n",
       "      <td>11.963413</td>\n",
       "      <td>Oh. That's so Monica can keep track. That way ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.418739</td>\n",
       "      <td>3.435926</td>\n",
       "      <td>11.054657</td>\n",
       "      <td>35.521602</td>\n",
       "      <td>1.982503</td>\n",
       "      <td>8.586573</td>\n",
       "      <td>Push!</td>\n",
       "      <td>anger</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.502766</td>\n",
       "      <td>3.378611</td>\n",
       "      <td>3.375353</td>\n",
       "      <td>33.402619</td>\n",
       "      <td>32.220863</td>\n",
       "      <td>4.119789</td>\n",
       "      <td>Push 'em out, push 'em out, harder, harder.</td>\n",
       "      <td>joy</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.115883</td>\n",
       "      <td>5.157752</td>\n",
       "      <td>4.687754</td>\n",
       "      <td>33.257717</td>\n",
       "      <td>9.464384</td>\n",
       "      <td>6.316510</td>\n",
       "      <td>Push 'em out, push 'em out, way out!</td>\n",
       "      <td>anger</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       anger   disgust       fear        joy    sadness   surprise  \\\n",
       "0  25.369358  2.737392   2.352420  11.380595  28.313076  29.847160   \n",
       "1  15.117586  3.517425   7.371107  42.598438  19.432031  11.963413   \n",
       "2  39.418739  3.435926  11.054657  35.521602   1.982503   8.586573   \n",
       "3  23.502766  3.378611   3.375353  33.402619  32.220863   4.119789   \n",
       "4  41.115883  5.157752   4.687754  33.257717   9.464384   6.316510   \n",
       "\n",
       "                                                Chat Prediction      Gold  \n",
       "0  Why do all you're coffee mugs have numbers on ...   surprise  surprise  \n",
       "1  Oh. That's so Monica can keep track. That way ...        joy     anger  \n",
       "2                                              Push!      anger       joy  \n",
       "3        Push 'em out, push 'em out, harder, harder.        joy       joy  \n",
       "4               Push 'em out, push 'em out, way out!      anger       joy  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probabilities_6B = svm_linear_clf_6B.predict_proba(testDataVecs_6B)\n",
    "\n",
    "pred_labels_6B = []\n",
    "for predicted_label in y_pred_svm_6B:\n",
    "    pred_labels_6B.append(label_encoder.classes_[predicted_label])\n",
    "\n",
    "gold_labels_6B = []\n",
    "for gold_label in test_classes_6:\n",
    "    gold_labels_6B.append(label_encoder.classes_[gold_label])\n",
    "\n",
    "result_frame6B = pd.DataFrame(pred_probabilities_6B*100, columns=label_encoder.classes_)\n",
    "\n",
    "result_frame6B['Chat']= list(combined_dftest['Sent'])\n",
    "result_frame6B['Prediction']=pred_labels_6B\n",
    "result_frame6B['Gold']=gold_labels_6B\n",
    "\n",
    "result_frame6B.to_csv(\"result_frame6B.csv\")\n",
    "result_frame6B.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
